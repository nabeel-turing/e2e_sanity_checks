# This file is automatically generated by the MutationBuilder

def parse_docstring_to_tool_object(function_docstring_text, tool_function_identifier):
    """
    Converts a Python function's docstring into a Google Generative AI Tool object.

    This function parses a docstring to extract function metadata (name, description, 
    parameters) and creates a Tool object that can be used with Google's Generative AI 
    models for function calling capabilities. The docstring should follow standard Python 
    docstring conventions with clear parameter descriptions.

    Args:
        function_docstring_text (str): The docstring of the function to convert. Should contain 
                        clear descriptions of the function's purpose and parameters.
        tool_function_identifier (str): The name of the function that the docstring belongs to.
                           This will be used as the tool's function name.

    Returns:
        Dict[str, Any]: A JSON-serializable dictionary representing the Tool, with keys:
            - 'tool' (List[Dict]): A list containing a single dictionary
              that defines the function. This dictionary has the following keys:
                - 'name' (str): The name of the function.
                - 'description' (str): A detailed description of what the function does.
                - 'parameters' (Dict): A dictionary defining the function's parameters
                  in JSON Schema format, with keys:
                    - 'type' (str): The type of the schema, typically 'OBJECT'.
                    - 'properties' (Dict): A dictionary mapping parameter names to their
                      individual schemas (e.g., {'type': 'STRING', 'description': '...'}).
                    - 'required' (List[str], optional): A list of required parameter names.

    Raises:
        ValidationError: If the function_docstring_text or tool_function_identifier is not a string or is empty.
    """
    from call_llm.llm_execution import make_tool_from_docstring
    return make_tool_from_docstring(
        docstring=function_docstring_text,
        function_name=tool_function_identifier
    )


def create_generative_text(
    input_prompt_text,
    authentication_key,
    attachment_file_paths=None,
    model_behavior_instruction=None,
    ai_model_identifier='gemini-2.5-pro'
):
    """
    Generates a text response from a Google Generative AI model.

    This function sends a request to Google's Generative AI API and returns the 
    model's text response. It supports both text prompts and file uploads in the same request.

    Args:
        input_prompt_text (str): The user's prompt or question.
        authentication_key (str): Your Google AI API key for authentication. This should be 
                      a valid API key with access to the specified model.
        attachment_file_paths (Optional[List[str]]): A list of file paths to upload to the model.
        model_behavior_instruction (Optional[str]): A system-level instruction that sets the 
                                     context or behavior for the model. This is 
                                     separate from the user prompt and helps 
                                     guide the model's responses.
        ai_model_identifier (str): The name of the Google Generative AI model 
                         to use. Defaults to 'gemini-2.5-pro'.

    Returns:
        str: The text response generated by the LLM model.

    Raises:
        ValidationError: If any of the input parameters are invalid or empty.
        LLMExecutionError: If the model execution fails.
    """
    from call_llm.llm_execution import generate_llm_response
    return generate_llm_response(
        prompt=input_prompt_text,
        api_key=authentication_key,
        files=attachment_file_paths,
        system_prompt=model_behavior_instruction,
        model_name=ai_model_identifier
    )


def invoke_model_with_tool_support(
    user_request_text,
    service_api_key,
    uploaded_file_paths=None,
    target_model_name='gemini-2.5-pro',
    model_instructional_context=None,
    available_function_tools=None
):
    """
    Generates a response from a Google Generative AI model with function calling capabilities.

    This function extends the basic LLM response generation by adding support for 
    function calling. The model can choose to call one or more functions (tools) 
    based on the user's request, and the response includes both the model's text 
    response and any function calls that were made. If a function call is made, 
    the caller is responsible for running the function and sending the result 
    back to the model in a subsequent call using either `generate_llm_response()` or 
    `generate_llm_response_with_tools()`.

    Args:
        user_request_text (str): The user's prompt or question.
        service_api_key (str): Your Google AI API key for authentication. This should be 
                      a valid API key with access to the specified model.
        uploaded_file_paths (Optional[List[str]]): A list of file paths to upload to the model.
        target_model_name (str): The name of the Google Generative AI model 
                          to use. Defaults to 'gemini-2.5-pro'.
        model_instructional_context (Optional[str]): A system-level instruction that sets the 
                                     context or behavior for the model. This is 
                                     separate from the user content and helps 
                                     guide the model's responses.
        available_function_tools (Optional[List[Tool]]): A list of Tool objects that define functions the 
                                    model can call. Each can be created using 
                                    make_tool_from_docstring() or similar methods.

    Returns:
        Dict[str, Any]: A dictionary containing:
            - function_call (FunctionCall): The function call made by the model (if any), 
                             including function name and arguments. If not None, this is a request from the
                             model to execute a specific tool. It is the caller's responsibility to run this
                             function and send the result back to the model in a subsequent call.
            - response_text (str): The text response from the model. May be empty if a tool call is made.

    Raises:
        ValidationError: If any of the input parameters are invalid or empty.
        LLMExecutionError: If the model execution fails.
    """
    from call_llm.llm_execution import generate_llm_response_with_tools
    return generate_llm_response_with_tools(
        prompt=user_request_text,
        api_key=service_api_key,
        files=uploaded_file_paths,
        model_name=target_model_name,
        system_prompt=model_instructional_context,
        tools=available_function_tools
    )
