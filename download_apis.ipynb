{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SERVICE_ACCOUNT_FILE = 'turing-delivery-g-ga-e36eb2300714.json'\n",
    "\n",
    "# Combine scopes for both Drive and Sheets\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "]\n",
    "\n",
    "def authenticate_with_service_account():\n",
    "    \"\"\"Authenticate using a service account and return credentials.\"\"\"\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE,\n",
    "        scopes=SCOPES\n",
    "    )\n",
    "    return creds\n",
    "\n",
    "# Get the shared credentials object\n",
    "credentials = authenticate_with_service_account()\n",
    "drive_service = build(\"drive\", \"v3\", credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Download APIs Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_apis(VERSION=\"0.1.0\", download_datasets=False, save_directory='clean_workspace'):\n",
    "    import io\n",
    "    import os\n",
    "    import sys\n",
    "    import zipfile\n",
    "    import shutil\n",
    "    import re\n",
    "    # from google.colab import auth\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "    global drive_service\n",
    "    # Version to download\n",
    "    # VERSION = \"0.0.rev22final\" # Version of the API\n",
    "    \n",
    "    # Define paths\n",
    "    CONTENT_DIR = os.path.join(save_directory, VERSION)\n",
    "    if os.path.exists(CONTENT_DIR):\n",
    "        os.remove(CONTENT_DIR)\n",
    "    os.makedirs(CONTENT_DIR, exist_ok=True)\n",
    "    \n",
    "    APIS_DIR = os.path.join(CONTENT_DIR, 'APIs')\n",
    "    DBS_DIR = os.path.join(CONTENT_DIR, 'DBs')\n",
    "    SCRIPTS_DIR = os.path.join(CONTENT_DIR, 'Scripts')\n",
    "    FC_DIR = os.path.join(CONTENT_DIR, 'Schemas')\n",
    "    ZIP_PATH = os.path.join(CONTENT_DIR, f'APIs_V{VERSION}.zip')\n",
    "    \n",
    "    # Google Drive Folder ID where versioned APIs zip files are stored\n",
    "    APIS_FOLDER_ID = '1QpkAZxXhVFzIbm8qPGPRP1YqXEvJ4uD4'\n",
    "    \n",
    "    # List of items to extract from the zip file\n",
    "    ITEMS_TO_EXTRACT = ['APIs/', 'DBs/', 'Scripts/']\n",
    "    \n",
    "    # Clean up existing directories and files\n",
    "    for path in [APIS_DIR, DBS_DIR, SCRIPTS_DIR, FC_DIR, ZIP_PATH]:\n",
    "        if os.path.exists(path):\n",
    "            if os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "            else:\n",
    "                os.remove(path)\n",
    "    \n",
    "    # Authenticate and create the drive service\n",
    "    # auth.authenticate_user()\n",
    "    # drive_service = build('drive', 'v3')\n",
    "    # drive_service\n",
    "    # Helper function to download a file from Google Drive\n",
    "    def download_drive_file(service, file_id, output_path, file_name=None, show_progress=True):\n",
    "        \"\"\"Downloads a file from Google Drive\"\"\"\n",
    "        destination = output_path\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        with io.FileIO(destination, 'wb') as fh:\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "                if show_progress:\n",
    "                    print(f\"Download progress: {int(status.progress() * 100)}%\")\n",
    "    \n",
    "    \n",
    "    # 1. List files in the specified APIs folder\n",
    "    print(f\"Searching for APIs zip file with version {VERSION} in folder: {APIS_FOLDER_ID}...\")\n",
    "    apis_file_id = None\n",
    "    \n",
    "    try:\n",
    "        query = f\"'{APIS_FOLDER_ID}' in parents and trashed=false\"\n",
    "        results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "        files = results.get('files', [])\n",
    "        for file in files:\n",
    "            file_name = file.get('name', '')\n",
    "            if file_name.lower() == f'apis_v{VERSION.lower()}.zip':\n",
    "                apis_file_id = file.get('id')\n",
    "                print(f\"Found matching file: {file_name} (ID: {apis_file_id})\")\n",
    "                break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while listing files in Google Drive: {e}\")\n",
    "    \n",
    "    if not apis_file_id:\n",
    "        print(f\"Error: Could not find APIs zip file with version {VERSION} in the specified folder.\")\n",
    "        sys.exit(\"Required APIs zip file not found.\")\n",
    "    \n",
    "    # 2. Download the found APIs zip file\n",
    "    print(f\"Downloading APIs zip file with ID: {apis_file_id}...\")\n",
    "    download_drive_file(drive_service, apis_file_id, ZIP_PATH, file_name=f'APIs_V{VERSION}.zip')\n",
    "    \n",
    "    # 3. Extract specific items from the zip file to /content\n",
    "    print(f\"Extracting specific items from {ZIP_PATH} to {CONTENT_DIR}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "            zip_contents = zip_ref.namelist()\n",
    "    \n",
    "            for member in zip_contents:\n",
    "                extracted = False\n",
    "                for item_prefix in ITEMS_TO_EXTRACT:\n",
    "                  if member == item_prefix or member.startswith(item_prefix):\n",
    "                        zip_ref.extract(member, CONTENT_DIR)\n",
    "                        extracted = True\n",
    "                        break\n",
    "    \n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: The downloaded file at {ZIP_PATH} is not a valid zip file.\")\n",
    "        sys.exit(\"Invalid zip file downloaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during extraction: {e}\")\n",
    "        sys.exit(\"Extraction failed.\")\n",
    "    \n",
    "    \n",
    "    # 4. Clean up\n",
    "    if os.path.exists(ZIP_PATH):\n",
    "        os.remove(ZIP_PATH)\n",
    "    \n",
    "    # 5. Add APIs to path\n",
    "    if os.path.exists(APIS_DIR):\n",
    "        sys.path.append(APIS_DIR)\n",
    "    else:\n",
    "        print(f\"Error: APIS directory not found at {APIS_DIR} after extraction. Cannot add to path.\")\n",
    "    \n",
    "    # 6. Quick verification\n",
    "    # Check for the presence of the extracted items\n",
    "    verification_paths = [APIS_DIR, DBS_DIR, SCRIPTS_DIR]\n",
    "    all_present = True\n",
    "    print(\"\\nVerifying extracted items:\")\n",
    "    for path in verification_paths:\n",
    "        if os.path.exists(path):\n",
    "            print(f\"✅ {path} is present.\")\n",
    "        else:\n",
    "            print(f\"❌ {path} is MISSING!\")\n",
    "            all_present = False\n",
    "    \n",
    "    if all_present:\n",
    "        print(f\"\\n✅ Setup complete! Required items extracted to {CONTENT_DIR}.\")\n",
    "    else:\n",
    "        print(\"\\n❌ Setup failed! Not all required items were extracted.\")\n",
    "\n",
    "    # 7. Generate Schemas\n",
    "\n",
    "    # Add Scripts to path\n",
    "    if os.path.exists(CONTENT_DIR):\n",
    "        sys.path.append(CONTENT_DIR)\n",
    "    else:\n",
    "        print(f\"Error: CONTENT_DIR directory not found at {CONTENT_DIR} after extraction. Cannot add to path.\")\n",
    "    \n",
    "    from Scripts.FCSpec import generate_package_schema\n",
    "    \n",
    "    print(\"\\nGenerating FC Schemas\")\n",
    "    os.makedirs(FC_DIR, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Iterate through the packages in the /content/APIs directory\n",
    "    for package_name in os.listdir(APIS_DIR):\n",
    "        package_path = os.path.join(APIS_DIR, package_name)\n",
    "    \n",
    "        # Check if it's a directory (to avoid processing files)\n",
    "        if os.path.isdir(package_path):\n",
    "            # Call the function to generate schema for the current package\n",
    "            generate_package_schema(package_path, output_folder_path=FC_DIR)\n",
    "    print(f\"✅ Successfully generated {len(os.listdir(FC_DIR))} FC Schemas to {FC_DIR}\")\n",
    "\n",
    "    if download_datasets:\n",
    "        def download_drive_folder(service, folder_id, destination_path):\n",
    "            \"\"\"\n",
    "            Recursively downloads all files in a Google Drive folder using the `download_drive_file`\n",
    "            \"\"\"\n",
    "            os.makedirs(destination_path, exist_ok=True)\n",
    "        \n",
    "            query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "            page_token = None\n",
    "        \n",
    "            while True:\n",
    "                results = service.files().list(\n",
    "                    q=query,\n",
    "                    spaces='drive',\n",
    "                    fields='nextPageToken, files(id, name, mimeType)',\n",
    "                    pageToken=page_token\n",
    "                ).execute()\n",
    "        \n",
    "                for item in results.get('files', []):\n",
    "                    file_id = item['id']\n",
    "                    file_name = item['name']\n",
    "                    mime_type = item['mimeType']\n",
    "        \n",
    "                    if mime_type == 'application/vnd.google-apps.folder':\n",
    "                        # Recursively download subfolders\n",
    "                        new_path = os.path.join(destination_path, file_name)\n",
    "                        print(f\"Creating subfolder and downloading: {new_path}\")\n",
    "                        download_drive_folder(service, file_id, new_path)\n",
    "                    else:\n",
    "                        # Construct full file path and pass it as output_path\n",
    "                        full_path = os.path.join(destination_path, file_name)\n",
    "                        print(f\"Downloading file: {file_name} to {full_path}\")\n",
    "                        download_drive_file(service, file_id, full_path, file_name=file_name, show_progress=False)\n",
    "        \n",
    "                page_token = results.get('nextPageToken', None)\n",
    "                if not page_token:\n",
    "                    break\n",
    "        \n",
    "        # --- Configuration for Dataset Download ---\n",
    "        # This FOLDER_ID should contain the 'Quotewk.csv' file.\n",
    "        FOLDER_ID = \"1tZqZB1vAxp4TTxbPm6O2YjfkZD4FM-ml\"\n",
    "        # DATASET_FOLDER = \"./workspace/Datasets\"\n",
    "        DATASET_FOLDER = os.path.join(CONTENT_DIR, 'workspace/Datasets')\n",
    "        \n",
    "        print(f\"Starting download of folder {FOLDER_ID} to {DATASET_FOLDER}...\")\n",
    "        download_drive_folder(drive_service, FOLDER_ID, DATASET_FOLDER)\n",
    "        print(\"Dataset download complete.\")\n",
    "\n",
    "        # --- Configuration for WS Dataset Download ---\n",
    "        # This FOLDER_ID should contain the 'WS Multihop Datasets' file.\n",
    "        WS_DATA_ID = \"1kmXZ1oarBPlE0OQL52eGoc1xPbupJ1n9\"\n",
    "        WS_DATA_ZIP_PATH = os.path.join(CONTENT_DIR, 'WS_DATA.zip')\n",
    "        \n",
    "        print(f\"Downloading WS Dataset zip file with ID: {WS_DATA_ID}...\")\n",
    "        download_drive_file(drive_service, WS_DATA_ID, WS_DATA_ZIP_PATH, file_name=f'WS_DATA.zip')\n",
    "        print(\"Dataset download complete.\")\n",
    "        \n",
    "        # Extract the Datasets\n",
    "        WS_DATA_ZIP_PATH = os.path.join(CONTENT_DIR, 'WS_DATA.zip')\n",
    "        with zipfile.ZipFile(WS_DATA_ZIP_PATH, 'r') as zip_ref:\n",
    "            zip_ref.extractall(CONTENT_DIR)\n",
    "        print(f\"Extracted to {CONTENT_DIR}\")\n",
    "        \n",
    "        # Moving 'file_dataset_pb2.py' to root directory\n",
    "        src_path = os.path.join(CONTENT_DIR, 'WS_DATA', 'file_dataset_pb2.py')\n",
    "        dst_path = os.path.join(CONTENT_DIR, 'file_dataset_pb2.py')\n",
    "        \n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "            print(f\"Moved {src_path} to {dst_path}\")\n",
    "        else:\n",
    "            print(f\"Source file not found: {src_path}\")\n",
    "        \n",
    "        # Clean up\n",
    "        if os.path.exists(WS_DATA_ZIP_PATH):\n",
    "            os.remove(WS_DATA_ZIP_PATH)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for APIs zip file with version 0.1.0 in folder: 1QpkAZxXhVFzIbm8qPGPRP1YqXEvJ4uD4...\n",
      "Found matching file: APIs_V0.1.0.zip (ID: 1hLV2slrHhH0RquKU-8oWRJRs_nHh5CT_)\n",
      "Downloading APIs zip file with ID: 1hLV2slrHhH0RquKU-8oWRJRs_nHh5CT_...\n",
      "Download progress: 100%\n",
      "Extracting specific items from clean_workspace/0.1.0/APIs_V0.1.0.zip to clean_workspace/0.1.0...\n",
      "\n",
      "Verifying extracted items:\n",
      "✅ clean_workspace/0.1.0/APIs is present.\n",
      "✅ clean_workspace/0.1.0/DBs is present.\n",
      "✅ clean_workspace/0.1.0/Scripts is present.\n",
      "\n",
      "✅ Setup complete! Required items extracted to clean_workspace/0.1.0.\n",
      "\n",
      "Generating FC Schemas\n",
      "✅ notes_and_lists Schema generation complete: clean_workspace/0.1.0/Schemas/notes_and_lists.json\n",
      "\n",
      "\n",
      "Processing mutation notes_and_lists.mutations.m01...\n",
      "✅ notes_and_lists.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/notes_and_lists.json\n",
      "\n",
      "✅ google_maps Schema generation complete: clean_workspace/0.1.0/Schemas/google_maps.json\n",
      "\n",
      "\n",
      "Processing mutation google_maps.mutations.m01...\n",
      "✅ google_maps.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_maps.json\n",
      "\n",
      "Error: Could not find a valid _function_map in clean_workspace/0.1.0/APIs/common_utils/__init__.py.\n",
      "✅ google_home Schema generation complete: clean_workspace/0.1.0/Schemas/google_home.json\n",
      "\n",
      "\n",
      "Processing mutation google_home.mutations.m01...\n",
      "✅ google_home.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_home.json\n",
      "\n",
      "✅ google_calendar Schema generation complete: clean_workspace/0.1.0/Schemas/google_calendar.json\n",
      "\n",
      "\n",
      "Processing mutation google_calendar.mutations.m01...\n",
      "✅ google_calendar.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_calendar.json\n",
      "\n",
      "✅ device_setting Schema generation complete: clean_workspace/0.1.0/Schemas/device_setting.json\n",
      "\n",
      "\n",
      "Processing mutation device_setting.mutations.m01...\n",
      "✅ device_setting.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/device_setting.json\n",
      "\n",
      "✅ call_llm Schema generation complete: clean_workspace/0.1.0/Schemas/call_llm.json\n",
      "\n",
      "\n",
      "Processing mutation call_llm.mutations.m01...\n",
      "✅ call_llm.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/call_llm.json\n",
      "\n",
      "✅ generic_media Schema generation complete: clean_workspace/0.1.0/Schemas/generic_media.json\n",
      "\n",
      "\n",
      "Processing mutation generic_media.mutations.m01...\n",
      "✅ generic_media.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/generic_media.json\n",
      "\n",
      "✅ messages Schema generation complete: clean_workspace/0.1.0/Schemas/messages.json\n",
      "\n",
      "\n",
      "Processing mutation messages.mutations.m01...\n",
      "✅ messages.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/messages.json\n",
      "\n",
      "✅ google_sheets Schema generation complete: clean_workspace/0.1.0/Schemas/google_sheets.json\n",
      "\n",
      "\n",
      "Processing mutation google_sheets.mutations.m01...\n",
      "✅ google_sheets.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_sheets.json\n",
      "\n",
      "✅ google_chat Schema generation complete: clean_workspace/0.1.0/Schemas/google_chat.json\n",
      "\n",
      "\n",
      "Processing mutation google_chat.mutations.m01...\n",
      "✅ google_chat.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_chat.json\n",
      "\n",
      "✅ google_cloud_storage Schema generation complete: clean_workspace/0.1.0/Schemas/google_cloud_storage.json\n",
      "\n",
      "\n",
      "Processing mutation google_cloud_storage.mutations.m01...\n",
      "✅ google_cloud_storage.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_cloud_storage.json\n",
      "\n",
      "✅ puppeteer Schema generation complete: clean_workspace/0.1.0/Schemas/puppeteer.json\n",
      "\n",
      "\n",
      "Processing mutation puppeteer.mutations.m01...\n",
      "Error: Could not find a valid _function_map in clean_workspace/0.1.0/APIs/puppeteer/mutations/m01/__init__.py.\n",
      "✅ copilot Schema generation complete: clean_workspace/0.1.0/Schemas/copilot.json\n",
      "\n",
      "\n",
      "Processing mutation copilot.mutations.m01...\n",
      "✅ copilot.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/copilot.json\n",
      "\n",
      "✅ cursor Schema generation complete: clean_workspace/0.1.0/Schemas/cursor.json\n",
      "\n",
      "\n",
      "Processing mutation cursor.mutations.m01...\n",
      "✅ cursor.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/cursor.json\n",
      "\n",
      "✅ workday Schema generation complete: clean_workspace/0.1.0/Schemas/workday.json\n",
      "\n",
      "\n",
      "Processing mutation workday.mutations.m01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/cursor/mutations/m01/cursorAPI.py:128: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ workday.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/workday.json\n",
      "\n",
      "✅ azure Schema generation complete: clean_workspace/0.1.0/Schemas/azure.json\n",
      "\n",
      "\n",
      "Processing mutation azure.mutations.m01...\n",
      "✅ azure.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/azure.json\n",
      "\n",
      "✅ media_control Schema generation complete: clean_workspace/0.1.0/Schemas/media_control.json\n",
      "\n",
      "\n",
      "Processing mutation media_control.mutations.m01...\n",
      "✅ media_control.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/media_control.json\n",
      "\n",
      "✅ google_meet Schema generation complete: clean_workspace/0.1.0/Schemas/google_meet.json\n",
      "\n",
      "\n",
      "Processing mutation google_meet.mutations.m01...\n",
      "✅ google_meet.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_meet.json\n",
      "\n",
      "✅ google_maps_live Schema generation complete: clean_workspace/0.1.0/Schemas/google_maps_live.json\n",
      "\n",
      "\n",
      "Processing mutation google_maps_live.mutations.m01...\n",
      "✅ google_maps_live.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_maps_live.json\n",
      "\n",
      "✅ contacts Schema generation complete: clean_workspace/0.1.0/Schemas/contacts.json\n",
      "\n",
      "\n",
      "Processing mutation contacts.mutations.m01...\n",
      "✅ contacts.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/contacts.json\n",
      "\n",
      "✅ spotify Schema generation complete: clean_workspace/0.1.0/Schemas/spotify.json\n",
      "\n",
      "\n",
      "Processing mutation spotify.mutations.m01...\n",
      "✅ spotify.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/spotify.json\n",
      "\n",
      "✅ canva Schema generation complete: clean_workspace/0.1.0/Schemas/canva.json\n",
      "\n",
      "\n",
      "Processing mutation canva.mutations.m01...\n",
      "✅ canva.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/canva.json\n",
      "\n",
      "✅ shopify Schema generation complete: clean_workspace/0.1.0/Schemas/shopify.json\n",
      "\n",
      "\n",
      "Processing mutation shopify.mutations.m01...\n",
      "✅ shopify.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/shopify.json\n",
      "\n",
      "✅ terminal Schema generation complete: clean_workspace/0.1.0/Schemas/terminal.json\n",
      "\n",
      "\n",
      "Processing mutation terminal.mutations.m01...\n",
      "✅ terminal.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/terminal.json\n",
      "\n",
      "✅ youtube_tool Schema generation complete: clean_workspace/0.1.0/Schemas/youtube_tool.json\n",
      "\n",
      "\n",
      "Processing mutation youtube_tool.mutations.m01...\n",
      "✅ youtube_tool.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/youtube_tool.json\n",
      "\n",
      "✅ tool_explorer Schema generation complete: clean_workspace/0.1.0/Schemas/tool_explorer.json\n",
      "\n",
      "\n",
      "Processing mutation tool_explorer.mutations.m01...\n",
      "✅ tool_explorer.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/tool_explorer.json\n",
      "\n",
      "✅ retail Schema generation complete: clean_workspace/0.1.0/Schemas/retail.json\n",
      "\n",
      "\n",
      "Processing mutation retail.mutations.m01...\n",
      "✅ retail.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/retail.json\n",
      "\n",
      "\n",
      "Processing mutation retail.mutations.smaller_toolset...\n",
      "✅ retail.mutations.smaller_toolset Schema generation complete: clean_workspace/0.1.0/MutationSchemas/smaller_toolset/retail.json\n",
      "\n",
      "✅ bigquery Schema generation complete: clean_workspace/0.1.0/Schemas/bigquery.json\n",
      "\n",
      "\n",
      "Processing mutation bigquery.mutations.m01...\n",
      "✅ bigquery.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/bigquery.json\n",
      "\n",
      "✅ google_docs Schema generation complete: clean_workspace/0.1.0/Schemas/google_docs.json\n",
      "\n",
      "\n",
      "Processing mutation google_docs.mutations.m01...\n",
      "✅ google_docs.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_docs.json\n",
      "\n",
      "✅ gdrive Schema generation complete: clean_workspace/0.1.0/Schemas/gdrive.json\n",
      "\n",
      "\n",
      "Processing mutation gdrive.mutations.m01...\n",
      "✅ gdrive.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/gdrive.json\n",
      "\n",
      "✅ youtube Schema generation complete: clean_workspace/0.1.0/Schemas/youtube.json\n",
      "\n",
      "\n",
      "Processing mutation youtube.mutations.m01...\n",
      "✅ youtube.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/youtube.json\n",
      "\n",
      "✅ google_slides Schema generation complete: clean_workspace/0.1.0/Schemas/google_slides.json\n",
      "\n",
      "\n",
      "Processing mutation google_slides.mutations.m01...\n",
      "✅ google_slides.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_slides.json\n",
      "\n",
      "✅ mongodb Schema generation complete: clean_workspace/0.1.0/Schemas/mongodb.json\n",
      "\n",
      "\n",
      "Processing mutation mongodb.mutations.m01...\n",
      "✅ mongodb.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/mongodb.json\n",
      "\n",
      "✅ sapconcur Schema generation complete: clean_workspace/0.1.0/Schemas/sapconcur.json\n",
      "\n",
      "\n",
      "Processing mutation sapconcur.mutations.m01...\n",
      "✅ sapconcur.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/sapconcur.json\n",
      "\n",
      "✅ device_actions Schema generation complete: clean_workspace/0.1.0/Schemas/device_actions.json\n",
      "\n",
      "\n",
      "Processing mutation device_actions.mutations.m01...\n",
      "✅ device_actions.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/device_actions.json\n",
      "\n",
      "✅ supabase Schema generation complete: clean_workspace/0.1.0/Schemas/supabase.json\n",
      "\n",
      "\n",
      "Processing mutation supabase.mutations.m01...\n",
      "✅ supabase.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/supabase.json\n",
      "\n",
      "✅ hubspot Schema generation complete: clean_workspace/0.1.0/Schemas/hubspot.json\n",
      "\n",
      "\n",
      "Processing mutation hubspot.mutations.m01...\n",
      "✅ hubspot.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/hubspot.json\n",
      "\n",
      "✅ google_search Schema generation complete: clean_workspace/0.1.0/Schemas/google_search.json\n",
      "\n",
      "\n",
      "Processing mutation google_search.mutations.m01...\n",
      "✅ google_search.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_search.json\n",
      "\n",
      "✅ gemini_cli Schema generation complete: clean_workspace/0.1.0/Schemas/gemini_cli.json\n",
      "\n",
      "\n",
      "Processing mutation gemini_cli.mutations.m01...\n",
      "✅ gemini_cli.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/gemini_cli.json\n",
      "\n",
      "✅ home_assistant Schema generation complete: clean_workspace/0.1.0/Schemas/home_assistant.json\n",
      "\n",
      "\n",
      "Processing mutation home_assistant.mutations.m01...\n",
      "✅ home_assistant.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/home_assistant.json\n",
      "\n",
      "✅ jira Schema generation complete: clean_workspace/0.1.0/Schemas/jira.json\n",
      "\n",
      "\n",
      "Processing mutation jira.mutations.m01...\n",
      "✅ jira.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/jira.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/Users/nabeel/PycharmProjects/e2e_sanity_checks/clean_workspace/0.1.0/APIs/gemini_cli/mutations/m01/file_system_api.py:162: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ github Schema generation complete: clean_workspace/0.1.0/Schemas/github.json\n",
      "\n",
      "\n",
      "Processing mutation github.mutations.m01...\n",
      "✅ github.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/github.json\n",
      "\n",
      "✅ figma Schema generation complete: clean_workspace/0.1.0/Schemas/figma.json\n",
      "\n",
      "\n",
      "Processing mutation figma.mutations.m01...\n",
      "✅ figma.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/figma.json\n",
      "\n",
      "✅ github_actions Schema generation complete: clean_workspace/0.1.0/Schemas/github_actions.json\n",
      "\n",
      "\n",
      "Processing mutation github_actions.mutations.m01...\n",
      "✅ github_actions.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/github_actions.json\n",
      "\n",
      "✅ zendesk Schema generation complete: clean_workspace/0.1.0/Schemas/zendesk.json\n",
      "\n",
      "\n",
      "Processing mutation zendesk.mutations.m01...\n",
      "✅ zendesk.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/zendesk.json\n",
      "\n",
      "✅ google_people Schema generation complete: clean_workspace/0.1.0/Schemas/google_people.json\n",
      "\n",
      "\n",
      "Processing mutation google_people.mutations.m01...\n",
      "✅ google_people.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/google_people.json\n",
      "\n",
      "✅ mysql Schema generation complete: clean_workspace/0.1.0/Schemas/mysql.json\n",
      "\n",
      "\n",
      "Processing mutation mysql.mutations.m01...\n",
      "✅ mysql.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/mysql.json\n",
      "\n",
      "✅ reddit Schema generation complete: clean_workspace/0.1.0/Schemas/reddit.json\n",
      "\n",
      "\n",
      "Processing mutation reddit.mutations.m01...\n",
      "✅ reddit.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/reddit.json\n",
      "\n",
      "✅ confluence Schema generation complete: clean_workspace/0.1.0/Schemas/confluence.json\n",
      "\n",
      "\n",
      "Processing mutation confluence.mutations.m01...\n",
      "✅ confluence.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/confluence.json\n",
      "\n",
      "✅ phone Schema generation complete: clean_workspace/0.1.0/Schemas/phone.json\n",
      "\n",
      "\n",
      "Processing mutation phone.mutations.m01...\n",
      "✅ phone.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/phone.json\n",
      "\n",
      "✅ sdm Schema generation complete: clean_workspace/0.1.0/Schemas/sdm.json\n",
      "\n",
      "\n",
      "Processing mutation sdm.mutations.m01...\n",
      "✅ sdm.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/sdm.json\n",
      "\n",
      "✅ salesforce Schema generation complete: clean_workspace/0.1.0/Schemas/salesforce.json\n",
      "\n",
      "\n",
      "Processing mutation salesforce.mutations.m01...\n",
      "✅ salesforce.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/salesforce.json\n",
      "\n",
      "✅ slack Schema generation complete: clean_workspace/0.1.0/Schemas/slack.json\n",
      "\n",
      "\n",
      "Processing mutation slack.mutations.m01...\n",
      "✅ slack.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/slack.json\n",
      "\n",
      "✅ tiktok Schema generation complete: clean_workspace/0.1.0/Schemas/tiktok.json\n",
      "\n",
      "\n",
      "Processing mutation tiktok.mutations.m01...\n",
      "✅ tiktok.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/tiktok.json\n",
      "\n",
      "✅ service_template Schema generation complete: clean_workspace/0.1.0/Schemas/service_template.json\n",
      "\n",
      "\n",
      "Processing mutation service_template.mutations.m01...\n",
      "✅ service_template.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/service_template.json\n",
      "\n",
      "✅ code_execution Schema generation complete: clean_workspace/0.1.0/Schemas/code_execution.json\n",
      "\n",
      "\n",
      "Processing mutation code_execution.mutations.m01...\n",
      "✅ code_execution.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/code_execution.json\n",
      "\n",
      "✅ blender Schema generation complete: clean_workspace/0.1.0/Schemas/blender.json\n",
      "\n",
      "\n",
      "Processing mutation blender.mutations.m01...\n",
      "✅ blender.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/blender.json\n",
      "\n",
      "✅ authentication Schema generation complete: clean_workspace/0.1.0/Schemas/authentication.json\n",
      "\n",
      "\n",
      "Processing mutation authentication.mutations.m01...\n",
      "✅ authentication.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/authentication.json\n",
      "\n",
      "✅ airline Schema generation complete: clean_workspace/0.1.0/Schemas/airline.json\n",
      "\n",
      "\n",
      "Processing mutation airline.mutations.m01...\n",
      "✅ airline.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/airline.json\n",
      "\n",
      "✅ instagram Schema generation complete: clean_workspace/0.1.0/Schemas/instagram.json\n",
      "\n",
      "\n",
      "Processing mutation instagram.mutations.m01...\n",
      "✅ instagram.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/instagram.json\n",
      "\n",
      "✅ generic_reminders Schema generation complete: clean_workspace/0.1.0/Schemas/generic_reminders.json\n",
      "\n",
      "\n",
      "Processing mutation generic_reminders.mutations.m01...\n",
      "✅ generic_reminders.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/generic_reminders.json\n",
      "\n",
      "✅ notifications Schema generation complete: clean_workspace/0.1.0/Schemas/notifications.json\n",
      "\n",
      "\n",
      "Processing mutation notifications.mutations.m01...\n",
      "✅ notifications.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/notifications.json\n",
      "\n",
      "✅ gmail Schema generation complete: clean_workspace/0.1.0/Schemas/gmail.json\n",
      "\n",
      "\n",
      "Processing mutation gmail.mutations.m01...\n",
      "✅ gmail.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/gmail.json\n",
      "\n",
      "✅ whatsapp Schema generation complete: clean_workspace/0.1.0/Schemas/whatsapp.json\n",
      "\n",
      "\n",
      "Processing mutation whatsapp.mutations.m01...\n",
      "✅ whatsapp.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/whatsapp.json\n",
      "\n",
      "✅ clock Schema generation complete: clean_workspace/0.1.0/Schemas/clock.json\n",
      "\n",
      "\n",
      "Processing mutation clock.mutations.m01...\n",
      "✅ clock.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/clock.json\n",
      "\n",
      "✅ linkedin Schema generation complete: clean_workspace/0.1.0/Schemas/linkedin.json\n",
      "\n",
      "\n",
      "Processing mutation linkedin.mutations.m01...\n",
      "✅ linkedin.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/linkedin.json\n",
      "\n",
      "✅ stripe Schema generation complete: clean_workspace/0.1.0/Schemas/stripe.json\n",
      "\n",
      "\n",
      "Processing mutation stripe.mutations.m01...\n",
      "✅ stripe.mutations.m01 Schema generation complete: clean_workspace/0.1.0/MutationSchemas/m01/stripe.json\n",
      "\n",
      "Error: __init__.py not found in clean_workspace/0.1.0/APIs/generic_tools\n",
      "✅ Successfully generated 67 FC Schemas to clean_workspace/0.1.0/Schemas\n",
      "Starting download of folder 1tZqZB1vAxp4TTxbPm6O2YjfkZD4FM-ml to clean_workspace/0.1.0/workspace/Datasets...\n",
      "Downloading file: ICEQueries_Files_md5Checksum_17_July_2025.csv to clean_workspace/0.1.0/workspace/Datasets/ICEQueries_Files_md5Checksum_17_July_2025.csv\n",
      "Downloading file: B Plan Budget.csv to clean_workspace/0.1.0/workspace/Datasets/B Plan Budget.csv\n",
      "Downloading file: Operatorsexcavatio.csv to clean_workspace/0.1.0/workspace/Datasets/Operatorsexcavatio.csv\n",
      "Downloading file: libro_gastronomia.csv to clean_workspace/0.1.0/workspace/Datasets/libro_gastronomia.csv\n",
      "Downloading file: September-November 2021 Billing.csv to clean_workspace/0.1.0/workspace/Datasets/September-November 2021 Billing.csv\n",
      "Downloading file: NOVEMBER MP REPORT - axel bond.csv to clean_workspace/0.1.0/workspace/Datasets/NOVEMBER MP REPORT - axel bond.csv\n",
      "Downloading file: monte_sells.csv to clean_workspace/0.1.0/workspace/Datasets/monte_sells.csv\n",
      "Downloading file: PhenolicBoards.csv to clean_workspace/0.1.0/workspace/Datasets/PhenolicBoards.csv\n",
      "Downloading file: Company_finances_markup.csv to clean_workspace/0.1.0/workspace/Datasets/Company_finances_markup.csv\n",
      "Downloading file: prices_chapas.csv to clean_workspace/0.1.0/workspace/Datasets/prices_chapas.csv\n",
      "Downloading file: MARKAS S.A. BOX Sales.csv to clean_workspace/0.1.0/workspace/Datasets/MARKAS S.A. BOX Sales.csv\n",
      "Downloading file: Waiter_Hourly_Schedule.csv to clean_workspace/0.1.0/workspace/Datasets/Waiter_Hourly_Schedule.csv\n",
      "Downloading file: Untitled spreadsheet - Jill Norton.csv to clean_workspace/0.1.0/workspace/Datasets/Untitled spreadsheet - Jill Norton.csv\n",
      "Downloading file: Services - Dawn Alderson.csv to clean_workspace/0.1.0/workspace/Datasets/Services - Dawn Alderson.csv\n",
      "Downloading file: SC fancy customer survey Aug 2023_Nov 2023... - Aurore Munyeshyaka.csv to clean_workspace/0.1.0/workspace/Datasets/SC fancy customer survey Aug 2023_Nov 2023... - Aurore Munyeshyaka.csv\n",
      "Downloading file: base holii matterport - carla mccadden.csv to clean_workspace/0.1.0/workspace/Datasets/base holii matterport - carla mccadden.csv\n",
      "Downloading file: Vouchers_Dec_2023.csv to clean_workspace/0.1.0/workspace/Datasets/Vouchers_Dec_2023.csv\n",
      "Downloading file: Book_Classes.csv to clean_workspace/0.1.0/workspace/Datasets/Book_Classes.csv\n",
      "Downloading file: ExpensesSushiRest.csv to clean_workspace/0.1.0/workspace/Datasets/ExpensesSushiRest.csv\n",
      "Downloading file: EMERGENCIA 2023 YAKU.csv to clean_workspace/0.1.0/workspace/Datasets/EMERGENCIA 2023 YAKU.csv\n",
      "Downloading file: prices_chapas.csv to clean_workspace/0.1.0/workspace/Datasets/prices_chapas.csv\n",
      "Downloading file: monte_sells.csv to clean_workspace/0.1.0/workspace/Datasets/monte_sells.csv\n",
      "Downloading file: cdlm_purchases.csv to clean_workspace/0.1.0/workspace/Datasets/cdlm_purchases.csv\n",
      "Downloading file: invoices_tracking.csv to clean_workspace/0.1.0/workspace/Datasets/invoices_tracking.csv\n",
      "Downloading file: ControlPanel.csv to clean_workspace/0.1.0/workspace/Datasets/ControlPanel.csv\n",
      "Downloading file: MARKAS S.A. BOX Sales.csv to clean_workspace/0.1.0/workspace/Datasets/MARKAS S.A. BOX Sales.csv\n",
      "Downloading file: W Plan Budget.csv to clean_workspace/0.1.0/workspace/Datasets/W Plan Budget.csv\n",
      "Downloading file: trash_valet - Jordan Layne.csv to clean_workspace/0.1.0/workspace/Datasets/trash_valet - Jordan Layne.csv\n",
      "Downloading file: P Plan Budget.csv to clean_workspace/0.1.0/workspace/Datasets/P Plan Budget.csv\n",
      "Downloading file: PhenolicBoards.csv to clean_workspace/0.1.0/workspace/Datasets/PhenolicBoards.csv\n",
      "Downloading file: Final_sales.csv to clean_workspace/0.1.0/workspace/Datasets/Final_sales.csv\n",
      "Downloading file: base holii matterport - carla mccadden.csv to clean_workspace/0.1.0/workspace/Datasets/base holii matterport - carla mccadden.csv\n",
      "Downloading file: Decoration_Items_List_Abril.csv to clean_workspace/0.1.0/workspace/Datasets/Decoration_Items_List_Abril.csv\n",
      "Downloading file: BestBatterEtsySales  - Renae Fultz.csv to clean_workspace/0.1.0/workspace/Datasets/BestBatterEtsySales  - Renae Fultz.csv\n",
      "Downloading file: Services - Dawn Alderson.csv to clean_workspace/0.1.0/workspace/Datasets/Services - Dawn Alderson.csv\n",
      "Downloading file: price_list_2023.csv to clean_workspace/0.1.0/workspace/Datasets/price_list_2023.csv\n",
      "Downloading file: Decoration_Items_List_Abril.csv to clean_workspace/0.1.0/workspace/Datasets/Decoration_Items_List_Abril.csv\n",
      "Downloading file: MARKAS S.A. BOX Sales.csv to clean_workspace/0.1.0/workspace/Datasets/MARKAS S.A. BOX Sales.csv\n",
      "Downloading file: Earnings Report 2023-01-01 to 2023-03-31 - Ryan Meza.csv to clean_workspace/0.1.0/workspace/Datasets/Earnings Report 2023-01-01 to 2023-03-31 - Ryan Meza.csv\n",
      "Downloading file: September-November 2021 Billing.csv to clean_workspace/0.1.0/workspace/Datasets/September-November 2021 Billing.csv\n",
      "Downloading file: FINANCIAL TRANSACTIONS.csv to clean_workspace/0.1.0/workspace/Datasets/FINANCIAL TRANSACTIONS.csv\n",
      "Downloading file: supermarket_stock_december.csv to clean_workspace/0.1.0/workspace/Datasets/supermarket_stock_december.csv\n",
      "Downloading file: Cards Movements.csv to clean_workspace/0.1.0/workspace/Datasets/Cards Movements.csv\n",
      "Downloading file: Untitled spreadsheet - Jill Norton.csv to clean_workspace/0.1.0/workspace/Datasets/Untitled spreadsheet - Jill Norton.csv\n",
      "Downloading file: supermarket_sales_tffb.csv to clean_workspace/0.1.0/workspace/Datasets/supermarket_sales_tffb.csv\n",
      "Downloading file: POPEYES_ANNUALIZED_PROFIT.csv to clean_workspace/0.1.0/workspace/Datasets/POPEYES_ANNUALIZED_PROFIT.csv\n",
      "Downloading file: price_list_2023.csv to clean_workspace/0.1.0/workspace/Datasets/price_list_2023.csv\n",
      "Downloading file: Vouchers_Dec_2023.csv to clean_workspace/0.1.0/workspace/Datasets/Vouchers_Dec_2023.csv\n",
      "Downloading file: e_com.csv to clean_workspace/0.1.0/workspace/Datasets/e_com.csv\n",
      "Downloading file: envios_ventas_exterior.csv to clean_workspace/0.1.0/workspace/Datasets/envios_ventas_exterior.csv\n",
      "Downloading file: cash flow GapIng.csv to clean_workspace/0.1.0/workspace/Datasets/cash flow GapIng.csv\n",
      "Downloading file: cash flow GapIng.csv to clean_workspace/0.1.0/workspace/Datasets/cash flow GapIng.csv\n",
      "Creating subfolder and downloading: clean_workspace/0.1.0/workspace/Datasets/Whole set\n",
      "Downloading file: Quotewk.csv to clean_workspace/0.1.0/workspace/Datasets/Quotewk.csv\n",
      "Downloading file: ICEQueries_Files_md5Checksum.csv to clean_workspace/0.1.0/workspace/Datasets/ICEQueries_Files_md5Checksum.csv\n",
      "Downloading file: torque and flow performance.csv to clean_workspace/0.1.0/workspace/Datasets/torque and flow performance.csv\n",
      "Downloading file: eBay-ListingsSalesReport-Dec-22-2023-08_21_39-0700-12145337749 - Karina Arango.csv to clean_workspace/0.1.0/workspace/Datasets/eBay-ListingsSalesReport-Dec-22-2023-08_21_39-0700-12145337749 - Karina Arango.csv\n",
      "Downloading file: visits_2023-11-01 - Spencer Miller.csv to clean_workspace/0.1.0/workspace/Datasets/visits_2023-11-01 - Spencer Miller.csv\n",
      "Downloading file: CLIENTS AB USD_CLEAN.csv to clean_workspace/0.1.0/workspace/Datasets/CLIENTS AB USD_CLEAN.csv\n",
      "Downloading file: Sales_Report.csv to clean_workspace/0.1.0/workspace/Datasets/Sales_Report.csv\n",
      "Downloading file: Truck Repairs for 2023 - Sheet1 - Dr. Victoria Gamble.csv to clean_workspace/0.1.0/workspace/Datasets/Truck Repairs for 2023 - Sheet1 - Dr. Victoria Gamble.csv\n",
      "Downloading file: prodqualityanalysis.csv to clean_workspace/0.1.0/workspace/Datasets/prodqualityanalysis.csv\n",
      "Downloading file: GARDEN LOG - Visits (1) - Erica Redling.csv to clean_workspace/0.1.0/workspace/Datasets/GARDEN LOG - Visits (1) - Erica Redling.csv\n",
      "Downloading file: business users.csv to clean_workspace/0.1.0/workspace/Datasets/business users.csv\n",
      "Downloading file: Earnings And Placements - statement.csv - Jonathan Foster.csv to clean_workspace/0.1.0/workspace/Datasets/Earnings And Placements - statement.csv - Jonathan Foster.csv\n",
      "Downloading file: Clockify Detailed Time Report - 2023.csv to clean_workspace/0.1.0/workspace/Datasets/Clockify Detailed Time Report - 2023.csv\n",
      "Downloading file: Retrogasm sales 2023 1 - Rachel Robinson.csv to clean_workspace/0.1.0/workspace/Datasets/Retrogasm sales 2023 1 - Rachel Robinson.csv\n",
      "Downloading file: Construction_costs_delivery.csv to clean_workspace/0.1.0/workspace/Datasets/Construction_costs_delivery.csv\n",
      "Downloading file: Expenses_20152.csv to clean_workspace/0.1.0/workspace/Datasets/Expenses_20152.csv\n",
      "Downloading file: Vat_sales_ledger 02-2023.csv to clean_workspace/0.1.0/workspace/Datasets/Vat_sales_ledger 02-2023.csv\n",
      "Downloading file: Salary and Equity Data.csv to clean_workspace/0.1.0/workspace/Datasets/Salary and Equity Data.csv\n",
      "Downloading file: 2020 sales - Shannon O.csv to clean_workspace/0.1.0/workspace/Datasets/2020 sales - Shannon O.csv\n",
      "Downloading file: Comparison with Wal Mart Catalog Stock.csv to clean_workspace/0.1.0/workspace/Datasets/Comparison with Wal Mart Catalog Stock.csv\n",
      "Downloading file: burbujas_sales_july.csv to clean_workspace/0.1.0/workspace/Datasets/burbujas_sales_july.csv\n",
      "Downloading file: Wood purchased - Patrick Bernier.csv to clean_workspace/0.1.0/workspace/Datasets/Wood purchased - Patrick Bernier.csv\n",
      "Downloading file: Dairy Solids (fat+protein).csv to clean_workspace/0.1.0/workspace/Datasets/Dairy Solids (fat+protein).csv\n",
      "Downloading file: Prices July 2022 EQUILIBRIO.csv to clean_workspace/0.1.0/workspace/Datasets/Prices July 2022 EQUILIBRIO.csv\n",
      "Downloading file: payroll_sheet.csv to clean_workspace/0.1.0/workspace/Datasets/payroll_sheet.csv\n",
      "Downloading file: [External] order_items.csv to clean_workspace/0.1.0/workspace/Datasets/[External] order_items.csv\n",
      "Downloading file: orders - orders - Kimm Topping.csv to clean_workspace/0.1.0/workspace/Datasets/orders - orders - Kimm Topping.csv\n",
      "Downloading file: 2_Debits_and_Credits_Purchases.csv to clean_workspace/0.1.0/workspace/Datasets/2_Debits_and_Credits_Purchases.csv\n",
      "Downloading file: Content Delivery Data Set - Jacob Goldberg.csv to clean_workspace/0.1.0/workspace/Datasets/Content Delivery Data Set - Jacob Goldberg.csv\n",
      "Downloading file: Purchase_invoice_graphics_company.csv to clean_workspace/0.1.0/workspace/Datasets/Purchase_invoice_graphics_company.csv\n",
      "Downloading file: Accounting - Jake Chase.csv to clean_workspace/0.1.0/workspace/Datasets/Accounting - Jake Chase.csv\n",
      "Downloading file: Higher Ed Threads 2023 - Phil Nance.csv to clean_workspace/0.1.0/workspace/Datasets/Higher Ed Threads 2023 - Phil Nance.csv\n",
      "Downloading file: Cars_Sales_22-23.csv to clean_workspace/0.1.0/workspace/Datasets/Cars_Sales_22-23.csv\n",
      "Downloading file: COMAFI AND SUPER HISTORY.csv to clean_workspace/0.1.0/workspace/Datasets/COMAFI AND SUPER HISTORY.csv\n",
      "Downloading file: Survey Meters.csv to clean_workspace/0.1.0/workspace/Datasets/Survey Meters.csv\n",
      "Downloading file: Juana Events Rentals.csv to clean_workspace/0.1.0/workspace/Datasets/Juana Events Rentals.csv\n",
      "Downloading file: 2201_VoucherCheker.csv to clean_workspace/0.1.0/workspace/Datasets/2201_VoucherCheker.csv\n",
      "Downloading file: Blueprint_budget.csv to clean_workspace/0.1.0/workspace/Datasets/Blueprint_budget.csv\n",
      "Downloading file: Storage (version 1).csv - Sheet1 - Erica Redling.csv to clean_workspace/0.1.0/workspace/Datasets/Storage (version 1).csv - Sheet1 - Erica Redling.csv\n",
      "Downloading file: Productivity2.csv to clean_workspace/0.1.0/workspace/Datasets/Productivity2.csv\n",
      "Downloading file: Woodworking Class Data - Patrick Bernier.csv to clean_workspace/0.1.0/workspace/Datasets/Woodworking Class Data - Patrick Bernier.csv\n",
      "Downloading file: March Sales.csv to clean_workspace/0.1.0/workspace/Datasets/March Sales.csv\n",
      "Downloading file: Survey - Videogames - Brazil 2015 - Alexandre Papanis.csv to clean_workspace/0.1.0/workspace/Datasets/Survey - Videogames - Brazil 2015 - Alexandre Papanis.csv\n",
      "Downloading file: Wine Inventory - Andrew Nelson.csv to clean_workspace/0.1.0/workspace/Datasets/Wine Inventory - Andrew Nelson.csv\n",
      "Downloading file: Toggl Detailed Time Report - 2022.csv to clean_workspace/0.1.0/workspace/Datasets/Toggl Detailed Time Report - 2022.csv\n",
      "Downloading file: IllinoisChicago_SuiteRentals_Aug2023 - Dalron J. Robertson.csv to clean_workspace/0.1.0/workspace/Datasets/IllinoisChicago_SuiteRentals_Aug2023 - Dalron J. Robertson.csv\n",
      "Downloading file: Dataset for Solar Panel Cleaning - Nestor Sanchez.csv to clean_workspace/0.1.0/workspace/Datasets/Dataset for Solar Panel Cleaning - Nestor Sanchez.csv\n",
      "Downloading file: 2022 Districts Monthly Transfer Dataset.csv to clean_workspace/0.1.0/workspace/Datasets/2022 Districts Monthly Transfer Dataset.csv\n",
      "Downloading file: balance_sheet.csv to clean_workspace/0.1.0/workspace/Datasets/balance_sheet.csv\n",
      "Downloading file: Parcels_2023Q1_CO - Guillermo Pardon.csv to clean_workspace/0.1.0/workspace/Datasets/Parcels_2023Q1_CO - Guillermo Pardon.csv\n",
      "Downloading file: OOC-55 - William Webster (SickBoy).csv to clean_workspace/0.1.0/workspace/Datasets/OOC-55 - William Webster (SickBoy).csv\n",
      "Downloading file: Materials_CTM.csv to clean_workspace/0.1.0/workspace/Datasets/Materials_CTM.csv\n",
      "Downloading file: cash_flow_Bakery.csv to clean_workspace/0.1.0/workspace/Datasets/cash_flow_Bakery.csv\n",
      "Downloading file: chicken_groceries_prices.csv to clean_workspace/0.1.0/workspace/Datasets/chicken_groceries_prices.csv\n",
      "Downloading file: Data Set Remotasks - Anita Portnoy.csv to clean_workspace/0.1.0/workspace/Datasets/Data Set Remotasks - Anita Portnoy.csv\n",
      "Downloading file: financial_credits.csv to clean_workspace/0.1.0/workspace/Datasets/financial_credits.csv\n",
      "Downloading file: Cristine's Corner January - Cristine Marquez.csv to clean_workspace/0.1.0/workspace/Datasets/Cristine's Corner January - Cristine Marquez.csv\n",
      "Downloading file: Tecno_MP_activities-feeder_collection-20231206183310-efa71.csv to clean_workspace/0.1.0/workspace/Datasets/Tecno_MP_activities-feeder_collection-20231206183310-efa71.csv\n",
      "Downloading file: airbnb_tax_01_2023-01_2024 - Philip Ferraro.csv to clean_workspace/0.1.0/workspace/Datasets/airbnb_tax_01_2023-01_2024 - Philip Ferraro.csv\n",
      "Downloading file: Log_2016_2020_Redacted - Adam Johnson.csv to clean_workspace/0.1.0/workspace/Datasets/Log_2016_2020_Redacted - Adam Johnson.csv\n",
      "Downloading file: U0089_Clients.csv to clean_workspace/0.1.0/workspace/Datasets/U0089_Clients.csv\n",
      "Downloading file: MarAug2023_ProjInst_Dataset - Diana.csv to clean_workspace/0.1.0/workspace/Datasets/MarAug2023_ProjInst_Dataset - Diana.csv\n",
      "Downloading file: Vat_purchases_journal_02-2023.csv to clean_workspace/0.1.0/workspace/Datasets/Vat_purchases_journal_02-2023.csv\n",
      "Downloading file: ServerProcesses.csv to clean_workspace/0.1.0/workspace/Datasets/ServerProcesses.csv\n",
      "Downloading file: Bold21 Data set - orders_export_1.csv to clean_workspace/0.1.0/workspace/Datasets/Bold21 Data set - orders_export_1.csv\n",
      "Downloading file: Payroll_oct_16-31.csv to clean_workspace/0.1.0/workspace/Datasets/Payroll_oct_16-31.csv\n",
      "Downloading file: Expense_summary.csv to clean_workspace/0.1.0/workspace/Datasets/Expense_summary.csv\n",
      "Downloading file: KookyArtsAi DATABASE - Christy Rivers.csv to clean_workspace/0.1.0/workspace/Datasets/KookyArtsAi DATABASE - Christy Rivers.csv\n",
      "Downloading file: Sales_RLC2.csv to clean_workspace/0.1.0/workspace/Datasets/Sales_RLC2.csv\n",
      "Downloading file: Fragrance June.csv to clean_workspace/0.1.0/workspace/Datasets/Fragrance June.csv\n",
      "Downloading file: Vector360-TravelResponse - Ernesto Herrero.csv to clean_workspace/0.1.0/workspace/Datasets/Vector360-TravelResponse - Ernesto Herrero.csv\n",
      "Downloading file: sales.csv to clean_workspace/0.1.0/workspace/Datasets/sales.csv\n",
      "Downloading file: Paper_Pen_Pavilion_Sales_09_12 - Cordejah Walker.csv to clean_workspace/0.1.0/workspace/Datasets/Paper_Pen_Pavilion_Sales_09_12 - Cordejah Walker.csv\n",
      "Downloading file: EtsySoldOrders2021_2023 - Sara Gerges.csv to clean_workspace/0.1.0/workspace/Datasets/EtsySoldOrders2021_2023 - Sara Gerges.csv\n",
      "Downloading file: Student supplies delivery costs Fall 2023 - Robert Russell.csv to clean_workspace/0.1.0/workspace/Datasets/Student supplies delivery costs Fall 2023 - Robert Russell.csv\n",
      "Downloading file: KiltX Web3 Summits Anonymized Data Keri Kilty - keri kilty.csv to clean_workspace/0.1.0/workspace/Datasets/KiltX Web3 Summits Anonymized Data Keri Kilty - keri kilty.csv\n",
      "Downloading file: BurguerhouseJuly21.csv to clean_workspace/0.1.0/workspace/Datasets/BurguerhouseJuly21.csv\n",
      "Downloading file: mill_operations.csv to clean_workspace/0.1.0/workspace/Datasets/mill_operations.csv\n",
      "Downloading file: Store Survey - Patrick Bernier.csv to clean_workspace/0.1.0/workspace/Datasets/Store Survey - Patrick Bernier.csv\n",
      "Downloading file: Monthly Cash Flow.csv to clean_workspace/0.1.0/workspace/Datasets/Monthly Cash Flow.csv\n",
      "Downloading file: supplies.csv to clean_workspace/0.1.0/workspace/Datasets/supplies.csv\n",
      "Downloading file: public_lighting.csv to clean_workspace/0.1.0/workspace/Datasets/public_lighting.csv\n",
      "Downloading file: rtshare - Kris Best.csv to clean_workspace/0.1.0/workspace/Datasets/rtshare - Kris Best.csv\n",
      "Downloading file: First School Term 2023_2024 - Robert Russell.csv to clean_workspace/0.1.0/workspace/Datasets/First School Term 2023_2024 - Robert Russell.csv\n",
      "Downloading file: order.list.export 2023-12-22 (2) - MOZZAM SHAHID.csv to clean_workspace/0.1.0/workspace/Datasets/order.list.export 2023-12-22 (2) - MOZZAM SHAHID.csv\n",
      "Downloading file: R Plan Budget.csv to clean_workspace/0.1.0/workspace/Datasets/R Plan Budget.csv\n",
      "Downloading file: Report_periodical_records.csv to clean_workspace/0.1.0/workspace/Datasets/Report_periodical_records.csv\n",
      "Downloading file: Submission id - Miss Kaye Estacio.csv to clean_workspace/0.1.0/workspace/Datasets/Submission id - Miss Kaye Estacio.csv\n",
      "Downloading file: Product Dims.csv to clean_workspace/0.1.0/workspace/Datasets/Product Dims.csv\n",
      "Downloading file: SalesFiguresQ1Q2 - Travis Colahan.csv to clean_workspace/0.1.0/workspace/Datasets/SalesFiguresQ1Q2 - Travis Colahan.csv\n",
      "Downloading file: Campaigns BIMO.csv to clean_workspace/0.1.0/workspace/Datasets/Campaigns BIMO.csv\n",
      "Downloading file: prices_ss.csv to clean_workspace/0.1.0/workspace/Datasets/prices_ss.csv\n",
      "Downloading file: ABM_WAGES.csv to clean_workspace/0.1.0/workspace/Datasets/ABM_WAGES.csv\n",
      "Downloading file: Bill_A2.csv to clean_workspace/0.1.0/workspace/Datasets/Bill_A2.csv\n",
      "Downloading file: HEALTHCARE AFFILIATE MANAGEMENT.csv to clean_workspace/0.1.0/workspace/Datasets/HEALTHCARE AFFILIATE MANAGEMENT.csv\n",
      "Downloading file: Gwynstone.Originz.dat - Gwynne Rife.csv to clean_workspace/0.1.0/workspace/Datasets/Gwynstone.Originz.dat - Gwynne Rife.csv\n",
      "Downloading file: Purchase_orders_GAP_ZEN.csv to clean_workspace/0.1.0/workspace/Datasets/Purchase_orders_GAP_ZEN.csv\n",
      "Downloading file: data-export (3) - Harsh Bakshi.csv to clean_workspace/0.1.0/workspace/Datasets/data-export (3) - Harsh Bakshi.csv\n",
      "Downloading file: Waiters Cash_Sales.csv to clean_workspace/0.1.0/workspace/Datasets/Waiters Cash_Sales.csv\n",
      "Downloading file: Mama Milk Flow Data - paul miles.csv to clean_workspace/0.1.0/workspace/Datasets/Mama Milk Flow Data - paul miles.csv\n",
      "Downloading file: JAZ Ceramics.csv to clean_workspace/0.1.0/workspace/Datasets/JAZ Ceramics.csv\n",
      "Downloading file: AccumulatorReadingsReport.csv to clean_workspace/0.1.0/workspace/Datasets/AccumulatorReadingsReport.csv\n",
      "Downloading file: Checks.csv to clean_workspace/0.1.0/workspace/Datasets/Checks.csv\n",
      "Downloading file: Bank_accreditations.csv to clean_workspace/0.1.0/workspace/Datasets/Bank_accreditations.csv\n",
      "Downloading file: vaccinations_city_flores.csv to clean_workspace/0.1.0/workspace/Datasets/vaccinations_city_flores.csv\n",
      "Downloading file: Sheet1 - Brooks Chiro Rehab.csv to clean_workspace/0.1.0/workspace/Datasets/Sheet1 - Brooks Chiro Rehab.csv\n",
      "Downloading file: Values Survey - June 2023.csv to clean_workspace/0.1.0/workspace/Datasets/Values Survey - June 2023.csv\n",
      "Downloading file: ChemicalProductsApplications.csv to clean_workspace/0.1.0/workspace/Datasets/ChemicalProductsApplications.csv\n",
      "Downloading file: BurguerhouseJuly21csv.csv to clean_workspace/0.1.0/workspace/Datasets/BurguerhouseJuly21csv.csv\n",
      "Downloading file: TD_HET Shipping Report - Phil Nance.csv to clean_workspace/0.1.0/workspace/Datasets/TD_HET Shipping Report - Phil Nance.csv\n",
      "Downloading file: shop_orders_export_shop_id_5874055_from_2023-11-01_to_2023-11-30 - Phil Nance.csv to clean_workspace/0.1.0/workspace/Datasets/shop_orders_export_shop_id_5874055_from_2023-11-01_to_2023-11-30 - Phil Nance.csv\n",
      "Downloading file: endowment_gm.csv to clean_workspace/0.1.0/workspace/Datasets/endowment_gm.csv\n",
      "Downloading file: Transaction List - Dawn Alderson.csv to clean_workspace/0.1.0/workspace/Datasets/Transaction List - Dawn Alderson.csv\n",
      "Downloading file: high_portability_local_cellphone.csv to clean_workspace/0.1.0/workspace/Datasets/high_portability_local_cellphone.csv\n",
      "Downloading file: Technical_services.csv to clean_workspace/0.1.0/workspace/Datasets/Technical_services.csv\n",
      "Downloading file: MARKAS S.A. BOX Purchases.csv to clean_workspace/0.1.0/workspace/Datasets/MARKAS S.A. BOX Purchases.csv\n",
      "Downloading file: 2023-12-21_transactions_export - Bailey Talley.csv to clean_workspace/0.1.0/workspace/Datasets/2023-12-21_transactions_export - Bailey Talley.csv\n",
      "Downloading file: OCT-QA-Report-2023 - Marlene Portillo.csv to clean_workspace/0.1.0/workspace/Datasets/OCT-QA-Report-2023 - Marlene Portillo.csv\n",
      "Downloading file: Bookshop Sales and Inventory Dataset.csv to clean_workspace/0.1.0/workspace/Datasets/Bookshop Sales and Inventory Dataset.csv\n",
      "Downloading file: november_supermarket_sales_per_product.csv to clean_workspace/0.1.0/workspace/Datasets/november_supermarket_sales_per_product.csv\n",
      "Downloading file: Art Gallery Spending Log 2017 - Erica Redling.csv to clean_workspace/0.1.0/workspace/Datasets/Art Gallery Spending Log 2017 - Erica Redling.csv\n",
      "Downloading file: BranchTransac.csv to clean_workspace/0.1.0/workspace/Datasets/BranchTransac.csv\n",
      "Downloading file: Sparkle and Sash Sales Detail 1_1_2022-6_30_2022 - Sheet1 (1) - Sparkle Sash.csv to clean_workspace/0.1.0/workspace/Datasets/Sparkle and Sash Sales Detail 1_1_2022-6_30_2022 - Sheet1 (1) - Sparkle Sash.csv\n",
      "Downloading file: Cegin list of shifts of the month.csv to clean_workspace/0.1.0/workspace/Datasets/Cegin list of shifts of the month.csv\n",
      "Downloading file: Purchase_RLC.csv to clean_workspace/0.1.0/workspace/Datasets/Purchase_RLC.csv\n",
      "Downloading file: 2023 Inventory - Elisabeth Gracyalny.csv to clean_workspace/0.1.0/workspace/Datasets/2023 Inventory - Elisabeth Gracyalny.csv\n",
      "Downloading file: production_costs_Bakery.csv to clean_workspace/0.1.0/workspace/Datasets/production_costs_Bakery.csv\n",
      "Downloading file: metzeler_tires.csv to clean_workspace/0.1.0/workspace/Datasets/metzeler_tires.csv\n",
      "Downloading file: E Plan Budget.csv to clean_workspace/0.1.0/workspace/Datasets/E Plan Budget.csv\n",
      "Downloading file: Sales records  report_ 12_2021- 12_2023 (2 years) - Sheet1 - Chef Walt.csv to clean_workspace/0.1.0/workspace/Datasets/Sales records  report_ 12_2021- 12_2023 (2 years) - Sheet1 - Chef Walt.csv\n",
      "Downloading file: Sale_Detail.csv to clean_workspace/0.1.0/workspace/Datasets/Sale_Detail.csv\n",
      "Downloading file: Expenses_2015.csv to clean_workspace/0.1.0/workspace/Datasets/Expenses_2015.csv\n",
      "Downloading file: online_retail.csv to clean_workspace/0.1.0/workspace/Datasets/online_retail.csv\n",
      "Downloading file: Commercial_Inventory.csv to clean_workspace/0.1.0/workspace/Datasets/Commercial_Inventory.csv\n",
      "Downloading file: sales_data JAN 2020 through DEC 2021 - DARKOTHICA - Mel.csv to clean_workspace/0.1.0/workspace/Datasets/sales_data JAN 2020 through DEC 2021 - DARKOTHICA - Mel.csv\n",
      "Downloading file: Dairy 0051-01.csv to clean_workspace/0.1.0/workspace/Datasets/Dairy 0051-01.csv\n",
      "Downloading file: Champro SKU Specs.csv to clean_workspace/0.1.0/workspace/Datasets/Champro SKU Specs.csv\n",
      "Downloading file: Info_FTTH.xlsx - PPP_INFO.csv to clean_workspace/0.1.0/workspace/Datasets/Info_FTTH.xlsx - PPP_INFO.csv\n",
      "Downloading file: Delivery_Sales Report.csv to clean_workspace/0.1.0/workspace/Datasets/Delivery_Sales Report.csv\n",
      "Downloading file: Tecno_sales_2018-12-06_2023-12-06.csv to clean_workspace/0.1.0/workspace/Datasets/Tecno_sales_2018-12-06_2023-12-06.csv\n",
      "Downloading file: Children's White Sales.csv to clean_workspace/0.1.0/workspace/Datasets/Children's White Sales.csv\n",
      "Downloading file: data - Kayla Banger.csv to clean_workspace/0.1.0/workspace/Datasets/data - Kayla Banger.csv\n",
      "Downloading file: Stamping_Dataset.csv to clean_workspace/0.1.0/workspace/Datasets/Stamping_Dataset.csv\n",
      "Downloading file: LSC _ 2022_sales_activity_report - Casey Montante.csv to clean_workspace/0.1.0/workspace/Datasets/LSC _ 2022_sales_activity_report - Casey Montante.csv\n",
      "Downloading file: BUILDING EXPENSES.csv to clean_workspace/0.1.0/workspace/Datasets/BUILDING EXPENSES.csv\n",
      "Downloading file: BusinessReport-7-28-22 - Travis Colahan.csv to clean_workspace/0.1.0/workspace/Datasets/BusinessReport-7-28-22 - Travis Colahan.csv\n",
      "Downloading file: Bybit-Derivatives-TradeHistory-20221001-20230111 - Syed Jafri.csv to clean_workspace/0.1.0/workspace/Datasets/Bybit-Derivatives-TradeHistory-20221001-20230111 - Syed Jafri.csv\n",
      "Downloading file: Untitled spreadsheet - Melissa Jaycox.csv to clean_workspace/0.1.0/workspace/Datasets/Untitled spreadsheet - Melissa Jaycox.csv\n",
      "Downloading file: VF Sample Dataset - rafael guzman.csv to clean_workspace/0.1.0/workspace/Datasets/VF Sample Dataset - rafael guzman.csv\n",
      "Downloading file: SubSystemIO.csv to clean_workspace/0.1.0/workspace/Datasets/SubSystemIO.csv\n",
      "Downloading file: businesspayrolls.csv to clean_workspace/0.1.0/workspace/Datasets/businesspayrolls.csv\n",
      "Downloading file: C1_dbjg.csv to clean_workspace/0.1.0/workspace/Datasets/C1_dbjg.csv\n",
      "Dataset download complete.\n",
      "Downloading WS Dataset zip file with ID: 1kmXZ1oarBPlE0OQL52eGoc1xPbupJ1n9...\n",
      "Download progress: 100%\n",
      "Dataset download complete.\n",
      "Extracted to clean_workspace/0.1.0\n",
      "Moved clean_workspace/0.1.0/WS_DATA/file_dataset_pb2.py to clean_workspace/0.1.0/file_dataset_pb2.py\n"
     ]
    }
   ],
   "source": [
    "download_apis(download_datasets=True, save_directory='clean_workspace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
