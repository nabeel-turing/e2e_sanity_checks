{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import io\n",
    "import re\n",
    "# import sys\n",
    "import json\n",
    "import math\n",
    "# import copy\n",
    "# import time\n",
    "# import shlex\n",
    "# import shutil\n",
    "# import random\n",
    "# import pathlib\n",
    "# import subprocess\n",
    "# import traceback\n",
    "# import concurrent.futures\n",
    "\n",
    "# import docker\n",
    "# import nbformat\n",
    "# import gspread\n",
    "\n",
    "from pathlib import Path\n",
    "# from functools import partial\n",
    "from datetime import datetime\n",
    "# from tqdm.notebook import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# from typing import Callable, Dict, List, Sequence, Iterable, Union\n",
    "\n",
    "import pandas as pd\n",
    "# from rclone_python import rclone\n",
    "# from nbclient import NotebookClient\n",
    "# from rclone_python.remote_types import RemoteTypes\n",
    "\n",
    "# from google.auth import default\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build, Resource\n",
    "# from googleapiclient.http import BatchHttpRequest, MediaIoBaseDownload, MediaIoBaseUpload\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_FILE = 'turing-delivery-g-ga-e36eb2300714.json'\n",
    "\n",
    "# Combine scopes for both Drive and Sheets\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "]\n",
    "\n",
    "def authenticate_with_service_account():\n",
    "    \"\"\"Authenticate using a service account and return credentials.\"\"\"\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE,\n",
    "        scopes=SCOPES\n",
    "    )\n",
    "    return creds\n",
    "\n",
    "# Get the shared credentials object\n",
    "credentials = authenticate_with_service_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rich'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrich\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconsole\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrich\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtheme\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Theme\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# @title Logger Configs\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'rich'"
     ]
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "# @title Logger Configs\n",
    "custom_theme = Theme({\n",
    "    \"info\": \"cyan\",\n",
    "    \"warning\": \"magenta\",\n",
    "    \"error\": \"bold red\"\n",
    "})\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "class Logger:\n",
    "  @staticmethod\n",
    "  def log(message):\n",
    "    console.print(message, style=\"info\")\n",
    "\n",
    "  def error(message):\n",
    "    console.print(message, style=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title GoogleService Class\n",
    "class GoogleService:\n",
    "\n",
    "  @classmethod\n",
    "  def extract_file_id(cls, url):\n",
    "      patterns = [\n",
    "          r\"/spreadsheets/d/([^/]+)\",\n",
    "          r\"/file/d/([^/]+)\",     # Matches /file/d/{file_id}\n",
    "          r\"[?&]id=([^&]+)\",       # Matches ?id={file_id} or &id={file_id}\n",
    "          r\"/drive/([^/?#]+)\",     # Matches /drive/{file_id} and stops at /, ?, or #\n",
    "          r\"/folders/([^/]+)\"      # Matches /folders/{folder_id}\n",
    "      ]\n",
    "\n",
    "      for pattern in patterns:\n",
    "          match_ = re.search(pattern, url)\n",
    "          if match_:\n",
    "              return match_.group(1).strip()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title GoogleDrive Functionality\n",
    "class GoogleDrive(GoogleService):\n",
    "    \n",
    "    service = build(\"drive\", \"v3\", credentials=credentials)\n",
    "\n",
    "    @classmethod\n",
    "    def get_file_names_in_batch(cls, file_ids):\n",
    "        \"\"\"\n",
    "        Retrieves the names of multiple files from Google Drive in a single batch request.\n",
    "        \n",
    "        Args:\n",
    "            drive_service: An authenticated Google Drive API service object.\n",
    "            file_ids: A list of file IDs.\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary mapping file IDs to their names.\n",
    "        \"\"\"\n",
    "        file_names = []\n",
    "    \n",
    "        def callback(request_id, response, exception):\n",
    "            \"\"\"\n",
    "            Callback function to process the result of each individual request.\n",
    "            \"\"\"\n",
    "            if exception:\n",
    "                print(f\"Error for file ID {request_id}: {exception}\")\n",
    "                \n",
    "                file_names.append(\n",
    "                    {\n",
    "                        'colab_id': request_id,\n",
    "                        'colab_name': None\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                file_names.append(\n",
    "                    {\n",
    "                        'colab_id': request_id,\n",
    "                        'colab_name': response.get('name')\n",
    "                    }\n",
    "                )\n",
    "    \n",
    "        # Create a batch request with the callback\n",
    "        batch = cls.service.new_batch_http_request(callback=callback)\n",
    "    \n",
    "        # Add a 'files().get()' request for each file ID\n",
    "        for file_id in file_ids:\n",
    "            batch.add(\n",
    "                cls.service.files().get(\n",
    "                    fileId=file_id,\n",
    "                    fields='name',\n",
    "                    supportsAllDrives=True\n",
    "                ),\n",
    "                request_id=file_id  # Use the file ID to track each request\n",
    "            )\n",
    "    \n",
    "        # Execute the batch request\n",
    "        batch.execute()\n",
    "    \n",
    "        return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title GoogleSheets Functionality\n",
    "class GoogleSheet(GoogleService):\n",
    "\n",
    "  # service = build(\"sheets\", \"v4\")\n",
    "  service = build(\"sheets\", \"v4\", credentials=credentials)\n",
    "\n",
    "  @classmethod\n",
    "  def get_sheet_data(cls, sheet_id: str, tab_name: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Gets data from existing Google Sheet and returns it as Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        sheet_id: The ID of the existing Google Sheet.\n",
    "        tab_name: The desired name for the new tab.\n",
    "        filter_col [Optional]: column name to filter the data.\n",
    "        filter_val [Optional]: value to filter the data on.\n",
    "    \"\"\"\n",
    "    vals = (\n",
    "        cls.service.spreadsheets()\n",
    "        .values()\n",
    "        .get(spreadsheetId=sheet_id, range=tab_name)\n",
    "        .execute()\n",
    "        .get(\"values\", [])\n",
    "    )\n",
    "    if len(vals) > 0:\n",
    "      header = vals[0]\n",
    "      data_values = vals[1:]\n",
    "      max_columns = min(len(header), len(data_values[0]))\n",
    "      data_values = [row[:max_columns] for row in data_values]\n",
    "      header = header[:max_columns]\n",
    "      df = pd.DataFrame(data_values, columns=header)\n",
    "      df.columns = [column.strip() for column in df.columns]\n",
    "      filter_cols = [col.strip() for col in kwargs.keys()]\n",
    "      if filter_cols:\n",
    "        if all(col in df.columns for col in filter_cols):\n",
    "          query = \" & \".join([\n",
    "              f\"{col}=='{kwargs[col]}'\"\n",
    "              if isinstance(kwargs[col], str)\n",
    "              else f\"{col}=={kwargs[col]}\"\n",
    "              for col in filter_cols])\n",
    "          df = df.query(query)\n",
    "        else:\n",
    "          missing_cols = [col for col in filter_cols if col not in df.columns]\n",
    "          raise Exception(f\"Could not find column(s) in the sheet. {missing_cols}\")\n",
    "      return df\n",
    "    sheet_name = cls.get_spreadsheet_name_by_id(sheet_id)\n",
    "    raise Exception(f\"No data found in the Tab: {tab_name}. Sheet ID: {sheet_name}\")\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def tab_exists(cls, spreadsheet_id, tab_name):\n",
    "\n",
    "    spreadsheet_metadata = cls.service.spreadsheets().get(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        fields='sheets.properties'\n",
    "    ).execute()\n",
    "\n",
    "    sheets = spreadsheet_metadata.get('sheets', [])\n",
    "    for sheet in sheets:\n",
    "        properties = sheet.get('properties')\n",
    "        if properties and (properties.get('title') == tab_name):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def add_dataframe_to_sheet(cls, spreadsheet_id, df, tab_name, valueInputOption='RAW', drop_duplicates_on=['sample_id']):\n",
    "    \"\"\"\n",
    "    Adds a new tab to an existing Google Sheet and populates it with data from a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        spreadsheet_id: The ID of the existing Google Sheet.\n",
    "        df: The Pandas DataFrame to export.\n",
    "        tab_name: The desired name for the new tab.\n",
    "    \"\"\"\n",
    "    try:\n",
    "      if cls.tab_exists(spreadsheet_id, tab_name):\n",
    "        Logger.log(f\"Tab '{tab_name}' already exists in the spreadsheet.\")\n",
    "        existing_df = cls.get_sheet_data(spreadsheet_id, tab_name)\n",
    "        # TODO: Add dataframe validation check\n",
    "        Logger.log(f\"Existing Dataframe\")\n",
    "        Logger.log(existing_df.info())\n",
    "\n",
    "        combined_df = pd.concat([df, existing_df], ignore_index=True)\n",
    "        df_to_upload = combined_df.drop_duplicates(subset=drop_duplicates_on, keep='first', ignore_index=True)\n",
    "        Logger.log(f\"Combined Dataframe\")\n",
    "        Logger.log(df_to_upload.info())\n",
    "\n",
    "      else:\n",
    "        Logger.log(f\"Tab '{tab_name}' does not exist in the spreadsheet. Creating a new tab.\")\n",
    "        requests = [{\n",
    "            'addSheet': {\n",
    "                'properties': {\n",
    "                    'title': tab_name\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "        batch_update_body = {\n",
    "            'requests': requests\n",
    "        }\n",
    "        response = cls.service.spreadsheets().batchUpdate(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            body=batch_update_body\n",
    "        ).execute()\n",
    "        # Get the ID of the newly created sheet (optional, but useful)\n",
    "        new_sheet_id = response.get('replies')[0].get('addSheet').get('properties').get('sheetId')\n",
    "        Logger.log(f\"Successfully added new tab: '{tab_name}' with ID: {new_sheet_id}\")\n",
    "        df_to_upload = df\n",
    "\n",
    "      values = [df_to_upload.columns.tolist()] + df_to_upload.values.tolist()\n",
    "      Logger.log(f\"Uploading {len(df_to_upload)} rows to tab '{tab_name}'.\")\n",
    "      range_name = f\"'{tab_name}'!A1\" # Ensure tab name is quoted if it has spaces or special characters\n",
    "      body = {\n",
    "          'values': values\n",
    "      }\n",
    "      result = cls.service.spreadsheets().values().update(\n",
    "          spreadsheetId=spreadsheet_id,\n",
    "          range=range_name,\n",
    "          valueInputOption=valueInputOption,\n",
    "          body=body\n",
    "      ).execute()\n",
    "\n",
    "      Logger.log(f\"{result.get('updatedCells')} cells updated in tab '{tab_name}'.\")\n",
    "\n",
    "    except HttpError as err:\n",
    "      Logger.error(f\"An error occurred: {err}\")\n",
    "      if err.resp.status == 400: # Bad Request, often due to sheet name already existing\n",
    "        Logger.error(\"Error details: The tab name might already exist or the request is malformed.\")\n",
    "      elif err.resp.status == 403: # Forbidden, often due to incorrect permissions\n",
    "        Logger.error(\"Error details: Check your API permissions or if the service account/user has access to the sheet.\")\n",
    "      elif err.resp.status == 404: # Not Found, often due to incorrect spreadsheet ID\n",
    "        Logger.error(\"Error details: The spreadsheet ID might be incorrect.\")\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def get_spreadsheet_name_by_id(cls, spreadsheet_id):\n",
    "      \"\"\"\n",
    "      Retrieves the name (title) of a Google Spreadsheet given its ID.\n",
    "\n",
    "      Args:\n",
    "          spreadsheet_id: The ID of the Google Spreadsheet.\n",
    "\n",
    "      Returns:\n",
    "          The title of the spreadsheet, or None if an error occurs or spreadsheet is not found.\n",
    "      \"\"\"\n",
    "      try:\n",
    "          # Use spreadsheets().get() to retrieve metadata\n",
    "          # We only request the 'properties.title' field for efficiency\n",
    "          spreadsheet_metadata = cls.service.spreadsheets().get(\n",
    "              spreadsheetId=spreadsheet_id,\n",
    "              fields='properties.title'\n",
    "          ).execute()\n",
    "\n",
    "          # Extract the title from the properties\n",
    "          title = spreadsheet_metadata.get('properties', {}).get('title')\n",
    "          return title\n",
    "      except HttpError as error:\n",
    "          print(f'An error occurred: {error}')\n",
    "          if error.resp.status == 404:\n",
    "              print(f\"Spreadsheet with ID '{spreadsheet_id}' not found.\")\n",
    "          return None\n",
    "\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def add_dropdown_to_range(cls, spreadsheet_id: str, sheet_id: str,\n",
    "                            dropdown_options: list,\n",
    "                            range_start_row: int, range_end_row: int,\n",
    "                            range_start_col: int, range_end_col: int):\n",
    "    requests = [\n",
    "        {\n",
    "            'setDataValidation': {\n",
    "                'range': {\n",
    "                    'sheetId': sheet_id,\n",
    "                    'startRowIndex': range_start_row,\n",
    "                    'endRowIndex': range_end_row,\n",
    "                    'startColumnIndex': range_start_col,\n",
    "                    'endColumnIndex': range_end_col\n",
    "                },\n",
    "                'rule': {\n",
    "                    'condition': {\n",
    "                        'type': 'ONE_OF_LIST',\n",
    "                        'values': [{'userEnteredValue': option} for option in dropdown_options]\n",
    "                    },\n",
    "                    'strict': True,  # Users can only enter values from the list\n",
    "                    'showCustomUi': True, # Show dropdown arrow\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # --- Execute the batch update request ---\n",
    "    try:\n",
    "        body = {\n",
    "            'requests': requests\n",
    "        }\n",
    "        response = cls.service.spreadsheets().batchUpdate(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            body=body\n",
    "        ).execute()\n",
    "        print(f\"Dropdown added to Sheet ID {sheet_id}, Range row{range_start_row+1}:row{range_end_row}.\")\n",
    "        # You can inspect the response for more details if needed\n",
    "        # print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "  @classmethod\n",
    "  def get_sheet_id_by_name(cls, spreadsheet_id: str, tab_name: str):\n",
    "      \"\"\"\n",
    "      Retrieves the numerical Sheet ID (gid) for a given tab name within a spreadsheet.\n",
    "\n",
    "      Args:\n",
    "          spreadsheet_id (str): The ID of the Google Spreadsheet.\n",
    "          tab_name (str): The exact name (title) of the tab/sheet to find.\n",
    "\n",
    "      Returns:\n",
    "          int: The numerical sheet ID (gid) if found.\n",
    "          None: If an error occurs, the spreadsheet is not found, or the tab name is not found.\n",
    "      \"\"\"\n",
    "      try:\n",
    "          # Use spreadsheets().get() to retrieve metadata\n",
    "          # We only request 'sheets.properties' to get sheet IDs and titles efficiently\n",
    "          spreadsheet_metadata = cls.service.spreadsheets().get(\n",
    "              spreadsheetId=spreadsheet_id,\n",
    "              fields='sheets.properties'\n",
    "          ).execute()\n",
    "\n",
    "          sheets = spreadsheet_metadata.get('sheets', [])\n",
    "          for sheet in sheets:\n",
    "              properties = sheet.get('properties')\n",
    "              # Check if properties exist and if the title matches the tab_name\n",
    "              if properties and properties.get('title') == tab_name:\n",
    "                  return properties.get('sheetId') # Return the sheetId (gid)\n",
    "\n",
    "          # If the loop completes, the tab was not found\n",
    "          print(f\"Tab '{tab_name}' not found in spreadsheet with ID '{spreadsheet_id}'.\")\n",
    "          return None\n",
    "      except HttpError as error:\n",
    "          if error.resp.status == 404:\n",
    "              print(f\"Spreadsheet with ID '{spreadsheet_id}' not found. Error: {error}\")\n",
    "          else:\n",
    "              print(f'An HTTP error occurred: {error}')\n",
    "          return None\n",
    "      except Exception as e:\n",
    "          print(f\"An unexpected error occurred while retrieving sheet ID for tab '{tab_name}': {e}\")\n",
    "          return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch & Download Colabs / Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sample_id  222 non-null    object\n",
      " 1   colab_url  222 non-null    object\n",
      " 2   status     222 non-null    object\n",
      " 3   colab_id   222 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 7.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sheet_id = \"1V6IyjZMqXcQ07zc0naOm6cbYySKLxN95GRjuqLKzVDU\"\n",
    "data_tab = \"auto_qc_data\"\n",
    "\n",
    "colabs_df = GoogleSheet.get_sheet_data(sheet_id, data_tab)\n",
    "\n",
    "# colabs_df = colabs_df.loc[(colabs_df['status'] == \"FALSE\")]\n",
    "\n",
    "# colabs_df = colabs_df.loc[((colabs_df['w/o'] != 'No Error Found') | (colabs_df['with'] != 'No Error Found')) & (colabs_df['status'] == 'Needs Fixes')]\n",
    "\n",
    "colabs_df['colab_id'] = colabs_df['colab_url'].apply(GoogleService.extract_file_id)\n",
    "colabs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   colab_id    222 non-null    object\n",
      " 1   colab_name  222 non-null    object\n",
      " 2   sample_id   222 non-null    object\n",
      " 3   colab_url   222 non-null    object\n",
      " 4   status      222 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "colab_names = []\n",
    "name_request_batch_size = 99\n",
    "for start in range(0, len(colabs_df['colab_id']), name_request_batch_size):\n",
    "    colab_names += GoogleDrive.get_file_names_in_batch(colabs_df['colab_id'].tolist()[start:start+name_request_batch_size])\n",
    "colab_name_df = pd.DataFrame(colab_names)\n",
    "colab_name_df = colab_name_df[~colab_name_df['colab_name'].isna()]\n",
    "colabs_df = pd.merge(colab_name_df, colabs_df, on='colab_id')\n",
    "# colabs_df = colabs_df.drop_duplicates(['colab_id'])\n",
    "colabs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Batches and Configuration Files for Docker Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Batches: 45\n",
      "Max Samples Per Batch: 5\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(list(set(colabs_df['colab_id'])))\n",
    "max_container = 50\n",
    "max_batch_size = math.ceil(total_samples / max_container)\n",
    "print(f'Max Batches: {math.ceil(total_samples/max_batch_size)}\\nMax Samples Per Batch: {max_batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = '0.1.0'\n",
    "notebooks = [{'path': notebook, 'api_version': api_version} for notebook in list(set(colabs_df['colab_id']))]\n",
    "notebooks_df = pd.DataFrame(notebooks)\n",
    "for idx, api_version in enumerate(set(notebooks_df['api_version'])):\n",
    "    count_notebooks = len(notebooks_df[notebooks_df['api_version']==api_version])\n",
    "    batches = []\n",
    "    for idx in range(count_notebooks):\n",
    "        batches.append(idx//max_batch_size)\n",
    "    batch_ids = [f\"{api_version}_{batch}\" for batch in batches]\n",
    "    notebooks_df.loc[notebooks_df['api_version'] == api_version, 'batch_id'] = batch_ids\n",
    "\n",
    "notebooks_df.to_csv('execution_configs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Local Run (where you have root access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Validating Host Environment ---\n",
      "✅ Docker client connected.\n",
      "\n",
      "--- Step 2: Preparing Host Directories ---\n",
      "✅ Created log directory for this run at: /Users/nabeel/PycharmProjects/e2e_sanity_checks/execution_logs/sanity_check_20250822_123517\n",
      "✅ Created result directory for this run at: /Users/nabeel/PycharmProjects/e2e_sanity_checks/results/sanity_check_20250822_123517\n",
      "✅ Created result directory for this run at: /Users/nabeel/PycharmProjects/e2e_sanity_checks/executed_notebooks/sanity_check_20250822_123517\n",
      "\n",
      "--- Step 4: Launching Containers in Parallel ---\n",
      "  -> Launching container 'sanity_check_20250822_123517-0' for batch 0...\n",
      "  -> Launching container 'sanity_check_20250822_123517-1' for batch 1...\n",
      "  -> Launching container 'sanity_check_20250822_123517-2' for batch 2...\n",
      "  -> Launching container 'sanity_check_20250822_123517-3' for batch 3...\n",
      "  -> Launching container 'sanity_check_20250822_123517-4' for batch 4...\n",
      "\n",
      "--- Step 5: Waiting for All Containers to Finish ---\n",
      "  -> ✅ SUCCESS | Container 'sanity_check_20250822_123517-0' finished with exit code 0.\n",
      "  -> ✅ SUCCESS | Container 'sanity_check_20250822_123517-1' finished with exit code 0.\n",
      "  -> ✅ SUCCESS | Container 'sanity_check_20250822_123517-2' finished with exit code 0.\n",
      "  -> ✅ SUCCESS | Container 'sanity_check_20250822_123517-3' finished with exit code 0.\n",
      "  -> ✅ SUCCESS | Container 'sanity_check_20250822_123517-4' finished with exit code 0.\n",
      "\n",
      "--- Orchestration Complete ---\n",
      "📄 All results and logs are stored in: /Users/nabeel/PycharmProjects/e2e_sanity_checks/execution_logs/sanity_check_20250822_123517\n",
      "Finished Docker Run. Time Taken: 164 Seconds\n"
     ]
    }
   ],
   "source": [
    "import sanity_orchestrator_with_download as orchestrator\n",
    "\n",
    "# orchestrator.DOCKER_IMAGE = 'gen-agents-auto-qc'\n",
    "\n",
    "exec_config = pd.read_csv(\"execution_configs.csv\")\n",
    "run_identifiers = list(set(exec_config['batch_id']))\n",
    "run_identifiers.sort()\n",
    "run_identifiers[:5]\n",
    "\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    run_name = f'sanity_check_{start_time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "    orchestrator.run_orchestration(run_name, run_identifiers[:5], 'Colab')\n",
    "    print(f\"Finished Docker Run. Time Taken: {(datetime.now()-start_time).seconds} Seconds\")\n",
    "except (FileNotFoundError, FileExistsError, ConnectionError) as e:\n",
    "    print(f\"\\n❌ A critical error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For where you need to use sudo to run docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:sudo: a password is required\n"
     ]
    }
   ],
   "source": [
    "!sudo .venv/bin/python runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                                Non-Null Count  Dtype \n",
      "---  ------                                                --------------  ----- \n",
      " 0   notebook                                              35 non-null     object\n",
      " 1   contains_golden_answer                                35 non-null     bool  \n",
      " 2   contains_final_assert                                 35 non-null     bool  \n",
      " 3   script_passed                                         35 non-null     bool  \n",
      " 4   script_failure_msg                                    35 non-null     object\n",
      " 5   Set Up - Install Dependencies and Clone Repositories  35 non-null     object\n",
      " 6   Set Up - Import APIs and initiate DBs                 35 non-null     object\n",
      " 7   Final Assertion_NO_ACTION                             35 non-null     object\n",
      " 8   Initial Assertion                                     35 non-null     object\n",
      " 9   Action                                                35 non-null     object\n",
      " 10  Final Assertion                                       35 non-null     object\n",
      "dtypes: bool(3), object(8)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "output_dir = f'results/{run_name}'\n",
    "output_files = os.listdir(output_dir)\n",
    "complete_data = []\n",
    "for file in output_files:\n",
    "    full_path = Path(output_dir) / file\n",
    "    with open(full_path, 'r') as f:\n",
    "        complete_data += json.load(f)['result']\n",
    "# Use json_normalize to flatten the data\n",
    "sanity_df = pd.json_normalize(complete_data)\n",
    "sanity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_FAILED_ASSERTION = 'FA Failed - Assertion Error'\n",
    "IA_FAILED_ASSERTION = 'IA Failed - Assertion Error'\n",
    "NON_ASSERTION_ERROR = 'Non Assertion Error'\n",
    "ASSERTION_ERROR = \"Assertion Error\"\n",
    "NO_ERROR_FOUND = 'No Error Found'\n",
    "UNDEFINED_ERROR = 'Undefined Error Type'\n",
    "\n",
    "NEEDS_FIXES = 'Needs Fixes'\n",
    "GOOD_TO_GO = 'Good To Go'\n",
    "NEEDS_MANUAL_REVIEW = 'Needs Manual Review'\n",
    "CHECK_NOT_EXECUTED = 'Check Not Executed'\n",
    "\n",
    "def add_error_type(error_message):\n",
    "    if error_message == \"\":\n",
    "        return NO_ERROR_FOUND\n",
    "    error_type = error_message.split('\\n')[0].split(':')[-1].strip()\n",
    "\n",
    "    if error_type != 'AssertionError':\n",
    "        return NON_ASSERTION_ERROR\n",
    "    if error_type == 'AssertionError':\n",
    "        return ASSERTION_ERROR\n",
    "\n",
    "    return UNDEFINED_ERROR\n",
    "\n",
    "def get_auto_qc_status(row):\n",
    "    init_status = row['Execution Status Initialisation']\n",
    "    status_fa_no_action = row['Execution Status FA w/o Action']\n",
    "    status_ia = row['Execution Status IA']\n",
    "    status_action = row['Execution Status Action']\n",
    "    status_fa = row['Execution Status FA'] \n",
    "    contains_final_assert = row['contains_final_assert']\n",
    "    script_success = row['script_passed']\n",
    "\n",
    "\n",
    "    status = \"\"\n",
    "    message = \"\"\n",
    "    \n",
    "    if not script_success:\n",
    "        status = NEEDS_FIXES\n",
    "        message = \"Failed: Script to run Auto QC failed\"\n",
    "        return pd.Series((status, message))\n",
    "    \n",
    "    if NON_ASSERTION_ERROR in [init_status, status_fa_no_action, status_ia, status_action, status_fa]:\n",
    "        status = NEEDS_FIXES\n",
    "        message = \"Failed: One of the code block contains Non Assertion Error(s)\"\n",
    "\n",
    "    elif ASSERTION_ERROR in [status_ia]:\n",
    "        status = NEEDS_FIXES\n",
    "        message = \"Failed: Assertion Failure in Initial Assertion.\"\n",
    "\n",
    "    elif ASSERTION_ERROR in [status_fa]:\n",
    "        status = NEEDS_FIXES\n",
    "        message = \"Failed: Final Assertion Failure even when Action is executed. Either Final Assertion or Action needs to be fixed.\"\n",
    "\n",
    "    elif ASSERTION_ERROR in [status_fa_no_action]:\n",
    "        status = GOOD_TO_GO\n",
    "        message = \"Passes: All Steps executed successfully and FA failed w/o action.\"\n",
    "        \n",
    "    else:\n",
    "        if all(status==NO_ERROR_FOUND for status in [init_status, status_fa_no_action, status_ia, status_action, status_fa]):\n",
    "            if contains_final_assert:\n",
    "                status = NEEDS_FIXES\n",
    "                message = \"Failed: If FA is present, it must fail in absense of the action\"\n",
    "            else:\n",
    "                status = GOOD_TO_GO\n",
    "                message = \"Passed: No FA block found so FA without action is expected to pass.\"\n",
    "        \n",
    "    return pd.Series((status, message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['notebook', 'contains_golden_answer', 'contains_final_assert',\n",
       "       'script_passed', 'script_failure_msg',\n",
       "       'Set Up - Install Dependencies and Clone Repositories',\n",
       "       'Set Up - Import APIs and initiate DBs', 'Final Assertion_NO_ACTION',\n",
       "       'Initial Assertion', 'Action', 'Final Assertion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Auto QC Status\n",
       "Good To Go     31\n",
       "Needs Fixes     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_df['Execution Status Install Dependencies and Clone Repositories'] = sanity_df['Set Up - Install Dependencies and Clone Repositories'].apply(add_error_type)\n",
    "sanity_df['Execution Status Initialisation'] = sanity_df['Set Up - Import APIs and initiate DBs'].apply(add_error_type)\n",
    "sanity_df['Execution Status FA w/o Action'] = sanity_df['Final Assertion_NO_ACTION'].apply(add_error_type)\n",
    "sanity_df['Execution Status IA'] = sanity_df['Initial Assertion'].apply(add_error_type)\n",
    "sanity_df['Execution Status Action'] = sanity_df['Action'].apply(add_error_type)\n",
    "sanity_df['Execution Status FA'] = sanity_df['Final Assertion'].apply(add_error_type)\n",
    "\n",
    "sanity_df = sanity_df.rename(columns={'notebook': 'colab_id'})\n",
    "\n",
    "sanity_df[['Auto QC Status', 'Auto QC Message']] = sanity_df.apply(get_auto_qc_status, axis=1)\n",
    "sanity_df['Auto QC Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_id</th>\n",
       "      <th>Auto QC Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10JFRQt1YnHmkA6X5PdeblqwtjxE-x2b5</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10f0vvJUTIYQPJO0WeIpNr1vEiUkLi2qS</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11hXpAfl9BGEodp4dFYRoboRce704z5It</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>145bFTPyeqF77isaP9uTU1f5v_hQqLv9u</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>151c0r7t6kqeFl5TNCQ-1aRgzp32BaqyZ</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16loMQwMXpQLm9ritJ2vzQn4UftbikaUE</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18a31wqZnCs_zMN13Ls2TKKvQhN2VVWXH</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1C2tSchsGNsqO5Eq6fk96SUCwYBG7Vxrk</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1DG9D64M2fXLYqTj_9lGSvcwCa5mtlAuk</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1GvNQs7rQl2ZpFTM1L70d8PW99McWyVAf</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1MN41-UjBE9GjzO01ZNuhvqtwwvkjle0K</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1NNT_4PqtFl8zsYH3YSX9gybvOfqbqUnW</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1PZ25p3xrm4jS2a04djRozJLNBi7uhvQS</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1PmGETXa8F_k96_HUp1347LjYOCju_zKT</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1Q17ut341xeHh8juMY5yDtyiU7O5Cffzf</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1WLs202u3t0ybjjkt4G1P6XqZ42FtMMUa</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1c0GznuEh09y29WMKYCnEmA_TBtkiq_Nm</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1cv4wVnMIfKwSUQBGckwIwZQOguHtO51g</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1eObP5DnvGXLj9hRh9hb-jV0Jrwg8edXa</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1i040qIU2bqSaCSsBZPXf-C7asZ_3olWf</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1mFcy_jCOkGlNqlW-T-bW1CORxc9v4ba1</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1mJzdQmWb1QkLb2AodwXsVFR40B4KqnYW</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1mY1k9RIaarki4hbi1p6GuE_IRnCWAeyz</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1nBoQx4MBSpQPZxPOje8DXYCtFYkwx4CJ</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1pVcET220i0VQQeJJtvlhtfs053EyTuO1</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1pg4XkSRj4hzxp3Q3weNm0k0scTBBqENd</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1r12lboibpIoaWoVYSNIbNZQq47hS6AbD</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1tpsVdc_KWMSt8rPYToJpz6D4YfidRwf5</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1v5DnQLsFf0E0TdDMv0eevOJBBsy0rTbf</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1x-ohcFhfGlZhk4F92RR_j-ee_trkBSE5</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1y78ATF54RRvXCXXmYqgCauZz0M2MRT3J</td>\n",
       "      <td>Good To Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Oz8O10fzIrjiqN0t-yrESeWz-Xe1vC4b</td>\n",
       "      <td>Needs Fixes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1b6qCBeiD9dIKk8CNlF3WVvIhvNpYqzwX</td>\n",
       "      <td>Needs Fixes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1ntAczmtrIzGQBKfh06og8mKtU0n4EnUK</td>\n",
       "      <td>Needs Fixes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1r5A5-DnuA8T8bcVucj6VA43ToUpjE_hs</td>\n",
       "      <td>Needs Fixes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             colab_id Auto QC Status\n",
       "8   10JFRQt1YnHmkA6X5PdeblqwtjxE-x2b5     Good To Go\n",
       "11  10f0vvJUTIYQPJO0WeIpNr1vEiUkLi2qS     Good To Go\n",
       "10  11hXpAfl9BGEodp4dFYRoboRce704z5It     Good To Go\n",
       "34  145bFTPyeqF77isaP9uTU1f5v_hQqLv9u     Good To Go\n",
       "15  151c0r7t6kqeFl5TNCQ-1aRgzp32BaqyZ     Good To Go\n",
       "33  16loMQwMXpQLm9ritJ2vzQn4UftbikaUE     Good To Go\n",
       "9   18a31wqZnCs_zMN13Ls2TKKvQhN2VVWXH     Good To Go\n",
       "26  1C2tSchsGNsqO5Eq6fk96SUCwYBG7Vxrk     Good To Go\n",
       "1   1DG9D64M2fXLYqTj_9lGSvcwCa5mtlAuk     Good To Go\n",
       "14  1GvNQs7rQl2ZpFTM1L70d8PW99McWyVAf     Good To Go\n",
       "30  1MN41-UjBE9GjzO01ZNuhvqtwwvkjle0K     Good To Go\n",
       "5   1NNT_4PqtFl8zsYH3YSX9gybvOfqbqUnW     Good To Go\n",
       "23  1PZ25p3xrm4jS2a04djRozJLNBi7uhvQS     Good To Go\n",
       "13  1PmGETXa8F_k96_HUp1347LjYOCju_zKT     Good To Go\n",
       "19  1Q17ut341xeHh8juMY5yDtyiU7O5Cffzf     Good To Go\n",
       "2   1WLs202u3t0ybjjkt4G1P6XqZ42FtMMUa     Good To Go\n",
       "3   1c0GznuEh09y29WMKYCnEmA_TBtkiq_Nm     Good To Go\n",
       "6   1cv4wVnMIfKwSUQBGckwIwZQOguHtO51g     Good To Go\n",
       "31  1eObP5DnvGXLj9hRh9hb-jV0Jrwg8edXa     Good To Go\n",
       "32  1i040qIU2bqSaCSsBZPXf-C7asZ_3olWf     Good To Go\n",
       "17  1mFcy_jCOkGlNqlW-T-bW1CORxc9v4ba1     Good To Go\n",
       "12  1mJzdQmWb1QkLb2AodwXsVFR40B4KqnYW     Good To Go\n",
       "29  1mY1k9RIaarki4hbi1p6GuE_IRnCWAeyz     Good To Go\n",
       "7   1nBoQx4MBSpQPZxPOje8DXYCtFYkwx4CJ     Good To Go\n",
       "24  1pVcET220i0VQQeJJtvlhtfs053EyTuO1     Good To Go\n",
       "28  1pg4XkSRj4hzxp3Q3weNm0k0scTBBqENd     Good To Go\n",
       "27  1r12lboibpIoaWoVYSNIbNZQq47hS6AbD     Good To Go\n",
       "16  1tpsVdc_KWMSt8rPYToJpz6D4YfidRwf5     Good To Go\n",
       "21  1v5DnQLsFf0E0TdDMv0eevOJBBsy0rTbf     Good To Go\n",
       "22  1x-ohcFhfGlZhk4F92RR_j-ee_trkBSE5     Good To Go\n",
       "4   1y78ATF54RRvXCXXmYqgCauZz0M2MRT3J     Good To Go\n",
       "0   1Oz8O10fzIrjiqN0t-yrESeWz-Xe1vC4b    Needs Fixes\n",
       "20  1b6qCBeiD9dIKk8CNlF3WVvIhvNpYqzwX    Needs Fixes\n",
       "25  1ntAczmtrIzGQBKfh06og8mKtU0n4EnUK    Needs Fixes\n",
       "18  1r5A5-DnuA8T8bcVucj6VA43ToUpjE_hs    Needs Fixes"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_df['script_passed'].value_counts()\n",
    "# sanity_df[sanity_df['Auto QC Status']=='Needs Fixes'].sort_values(['colab_id'])['colab_id']\n",
    "sanity_df.sort_values(['Auto QC Status', 'colab_id'])[['colab_id', 'Auto QC Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanity_df.to_csv('colab_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(colabs_df[['colab_id', 'sample_id']], sanity_df, on='colab_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>contains_golden_answer</th>\n",
       "      <th>contains_final_assert</th>\n",
       "      <th>script_passed</th>\n",
       "      <th>script_failure_msg</th>\n",
       "      <th>Set Up - Install Dependencies and Clone Repositories</th>\n",
       "      <th>Set Up - Import APIs and initiate DBs</th>\n",
       "      <th>Final Assertion_NO_ACTION</th>\n",
       "      <th>Initial Assertion</th>\n",
       "      <th>Action</th>\n",
       "      <th>Final Assertion</th>\n",
       "      <th>Execution Status Install Dependencies and Clone Repositories</th>\n",
       "      <th>Execution Status Initialisation</th>\n",
       "      <th>Execution Status FA w/o Action</th>\n",
       "      <th>Execution Status IA</th>\n",
       "      <th>Execution Status Action</th>\n",
       "      <th>Execution Status FA</th>\n",
       "      <th>Auto QC Status</th>\n",
       "      <th>Auto QC Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1WZF_kmS0Z78ZaSbRT3s69grD5EuvFTFg</td>\n",
       "      <td>1WZF_kmS0Z78ZaSbRT3s69grD5EuvFTFg</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: AssertionError\\nError Description: ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Assertion Error</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Good To Go</td>\n",
       "      <td>Passes: All Steps executed successfully and FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ddOYUiLnmflqzQQ7r9AYb3p-D-THcE7j</td>\n",
       "      <td>1ddOYUiLnmflqzQQ7r9AYb3p-D-THcE7j</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: AssertionError\\nError Description: ...</td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: NameError\\nError Description: name ...</td>\n",
       "      <td>ErrorType: AssertionError\\nError Description: ...</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Assertion Error</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Non Assertion Error</td>\n",
       "      <td>Assertion Error</td>\n",
       "      <td>Needs Fixes</td>\n",
       "      <td>Failed: One of the code block contains Non Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1oSI1iciSHXJd5WPS6gN-ZFl8NtK7F_rC</td>\n",
       "      <td>1oSI1iciSHXJd5WPS6gN-ZFl8NtK7F_rC</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: AssertionError\\nError Description: ...</td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: NameError\\nError Description: name ...</td>\n",
       "      <td>ErrorType: AssertionError\\nError Description: ...</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Assertion Error</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Non Assertion Error</td>\n",
       "      <td>Assertion Error</td>\n",
       "      <td>Needs Fixes</td>\n",
       "      <td>Failed: One of the code block contains Non Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1sOHIUssSmkKuXK8IASssFHaS9s1WMtgV</td>\n",
       "      <td>1sOHIUssSmkKuXK8IASssFHaS9s1WMtgV</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: NameError\\nError Description: name ...</td>\n",
       "      <td></td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Non Assertion Error</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Needs Fixes</td>\n",
       "      <td>Failed: One of the code block contains Non Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149DQS_PcWIVB81k248hatMQlQiJLk0wJ</td>\n",
       "      <td>149DQS_PcWIVB81k248hatMQlQiJLk0wJ</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ErrorType: CommandExecutionError\\nError Descri...</td>\n",
       "      <td></td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Non Assertion Error</td>\n",
       "      <td>No Error Found</td>\n",
       "      <td>Needs Fixes</td>\n",
       "      <td>Failed: One of the code block contains Non Ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            colab_id                          sample_id  \\\n",
       "0  1WZF_kmS0Z78ZaSbRT3s69grD5EuvFTFg  1WZF_kmS0Z78ZaSbRT3s69grD5EuvFTFg   \n",
       "1  1ddOYUiLnmflqzQQ7r9AYb3p-D-THcE7j  1ddOYUiLnmflqzQQ7r9AYb3p-D-THcE7j   \n",
       "2  1oSI1iciSHXJd5WPS6gN-ZFl8NtK7F_rC  1oSI1iciSHXJd5WPS6gN-ZFl8NtK7F_rC   \n",
       "3  1sOHIUssSmkKuXK8IASssFHaS9s1WMtgV  1sOHIUssSmkKuXK8IASssFHaS9s1WMtgV   \n",
       "4  149DQS_PcWIVB81k248hatMQlQiJLk0wJ  149DQS_PcWIVB81k248hatMQlQiJLk0wJ   \n",
       "\n",
       "   contains_golden_answer  contains_final_assert  script_passed  \\\n",
       "0                   False                   True           True   \n",
       "1                   False                   True           True   \n",
       "2                    True                   True           True   \n",
       "3                    True                  False           True   \n",
       "4                    True                  False           True   \n",
       "\n",
       "  script_failure_msg Set Up - Install Dependencies and Clone Repositories  \\\n",
       "0                N/A                                                        \n",
       "1                N/A                                                        \n",
       "2                N/A                                                        \n",
       "3                N/A                                                        \n",
       "4                N/A                                                        \n",
       "\n",
       "  Set Up - Import APIs and initiate DBs  \\\n",
       "0                                         \n",
       "1                                         \n",
       "2                                         \n",
       "3                                         \n",
       "4                                         \n",
       "\n",
       "                           Final Assertion_NO_ACTION Initial Assertion  \\\n",
       "0  ErrorType: AssertionError\\nError Description: ...                     \n",
       "1  ErrorType: AssertionError\\nError Description: ...                     \n",
       "2  ErrorType: AssertionError\\nError Description: ...                     \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "\n",
       "                                              Action  \\\n",
       "0                                                      \n",
       "1  ErrorType: NameError\\nError Description: name ...   \n",
       "2  ErrorType: NameError\\nError Description: name ...   \n",
       "3  ErrorType: NameError\\nError Description: name ...   \n",
       "4  ErrorType: CommandExecutionError\\nError Descri...   \n",
       "\n",
       "                                     Final Assertion  \\\n",
       "0                                                      \n",
       "1  ErrorType: AssertionError\\nError Description: ...   \n",
       "2  ErrorType: AssertionError\\nError Description: ...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "  Execution Status Install Dependencies and Clone Repositories  \\\n",
       "0                                     No Error Found             \n",
       "1                                     No Error Found             \n",
       "2                                     No Error Found             \n",
       "3                                     No Error Found             \n",
       "4                                     No Error Found             \n",
       "\n",
       "  Execution Status Initialisation Execution Status FA w/o Action  \\\n",
       "0                  No Error Found                Assertion Error   \n",
       "1                  No Error Found                Assertion Error   \n",
       "2                  No Error Found                Assertion Error   \n",
       "3                  No Error Found                 No Error Found   \n",
       "4                  No Error Found                 No Error Found   \n",
       "\n",
       "  Execution Status IA Execution Status Action Execution Status FA  \\\n",
       "0      No Error Found          No Error Found      No Error Found   \n",
       "1      No Error Found     Non Assertion Error     Assertion Error   \n",
       "2      No Error Found     Non Assertion Error     Assertion Error   \n",
       "3      No Error Found     Non Assertion Error      No Error Found   \n",
       "4      No Error Found     Non Assertion Error      No Error Found   \n",
       "\n",
       "  Auto QC Status                                    Auto QC Message  \n",
       "0     Good To Go  Passes: All Steps executed successfully and FA...  \n",
       "1    Needs Fixes  Failed: One of the code block contains Non Ass...  \n",
       "2    Needs Fixes  Failed: One of the code block contains Non Ass...  \n",
       "3    Needs Fixes  Failed: One of the code block contains Non Ass...  \n",
       "4    Needs Fixes  Failed: One of the code block contains Non Ass...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Auto QC Status\n",
       "Needs Fixes    191\n",
       "Good To Go      31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['Auto QC Status', 'Auto QC Message']] = merged_df.apply(get_auto_qc_status, axis=1)\n",
    "merged_df['Auto QC Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "script_passed\n",
       "True     176\n",
       "False     46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['script_passed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                                        Non-Null Count  Dtype \n",
      "---  ------                                                        --------------  ----- \n",
      " 0   colab_id                                                      222 non-null    object\n",
      " 1   sample_id                                                     222 non-null    object\n",
      " 2   contains_golden_answer                                        222 non-null    bool  \n",
      " 3   contains_final_assert                                         222 non-null    bool  \n",
      " 4   script_passed                                                 222 non-null    bool  \n",
      " 5   script_failure_msg                                            222 non-null    object\n",
      " 6   Set Up - Install Dependencies and Clone Repositories          222 non-null    object\n",
      " 7   Set Up - Import APIs and initiate DBs                         222 non-null    object\n",
      " 8   Final Assertion_NO_ACTION                                     222 non-null    object\n",
      " 9   Initial Assertion                                             222 non-null    object\n",
      " 10  Action                                                        222 non-null    object\n",
      " 11  Final Assertion                                               222 non-null    object\n",
      " 12  Execution Status Install Dependencies and Clone Repositories  222 non-null    object\n",
      " 13  Execution Status Initialisation                               222 non-null    object\n",
      " 14  Execution Status FA w/o Action                                222 non-null    object\n",
      " 15  Execution Status IA                                           222 non-null    object\n",
      " 16  Execution Status Action                                       222 non-null    object\n",
      " 17  Execution Status FA                                           222 non-null    object\n",
      " 18  Auto QC Status                                                222 non-null    object\n",
      " 19  Auto QC Message                                               222 non-null    object\n",
      "dtypes: bool(3), object(17)\n",
      "memory usage: 30.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_text(text):\n",
    "    return text[:49999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in merged_df.select_dtypes(include=['object', 'string']).columns.tolist():\n",
    "    merged_df[col] = merged_df[col].apply(trim_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Tab </span><span style=\"color: #008000; text-decoration-color: #008000\">'auto_qc_response_parser'</span><span style=\"color: #008080; text-decoration-color: #008080\"> does not exist in the spreadsheet. Creating a new tab.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mTab \u001b[0m\u001b[32m'auto_qc_response_parser'\u001b[0m\u001b[36m does not exist in the spreadsheet. Creating a new tab.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Successfully added new tab: </span><span style=\"color: #008000; text-decoration-color: #008000\">'auto_qc_response_parser'</span><span style=\"color: #008080; text-decoration-color: #008080\"> with ID: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1619311774</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mSuccessfully added new tab: \u001b[0m\u001b[32m'auto_qc_response_parser'\u001b[0m\u001b[36m with ID: \u001b[0m\u001b[1;36m1619311774\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Uploading </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">222</span><span style=\"color: #008080; text-decoration-color: #008080\"> rows to tab </span><span style=\"color: #008000; text-decoration-color: #008000\">'auto_qc_response_parser'</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mUploading \u001b[0m\u001b[1;36m222\u001b[0m\u001b[36m rows to tab \u001b[0m\u001b[32m'auto_qc_response_parser'\u001b[0m\u001b[36m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4460</span><span style=\"color: #008080; text-decoration-color: #008080\"> cells updated in tab </span><span style=\"color: #008000; text-decoration-color: #008000\">'auto_qc_response_parser'</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m4460\u001b[0m\u001b[36m cells updated in tab \u001b[0m\u001b[32m'auto_qc_response_parser'\u001b[0m\u001b[36m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_tab = 'auto_qc_response'\n",
    "GoogleSheet.add_dataframe_to_sheet(sheet_id, merged_df, output_tab, drop_duplicates_on = ['notebook'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
